cd "C:\Users\Tommaso\Django rest framework\Udemy Django\"

conda activate met5

django-admin startproject Metaglossario_Gestisco



cd "C:\Users\Tommaso\Django rest framework\Udemy Django\Metaglossario_Gestisco"

Inizializzare git al version control

git init

vs studio si tinge di verde e fa comparire master in git bash, che significa che siamo nel ramo master della nostra git repository

git add .
aggiunge tutto alla nostra repository

git commit -m "initial commit"

ora heroku

shh keys skippate

crea app metaglossario_gestisco  manualmente su heroku

heroku git:remote -a metaglossario-gestisco

#è il nome dell'app creata su heroku
gli sto dicendo che le cose le voglio caricare lì e non su un altra app

decoupling della secret key:

Heroku > app metaglossario > settings > reveal config vars > key=SECRET_KEY , Value =nv5f(pbo#92(e24l#)oqgbx2sjv6*7_kp)u8uswjmyg$mju(r&


KEY=SECRET_KEY

gunicorn, python-decouple e django-heroku già installati da prima

aggiungi import django_heroku in settings.py
from decouple import config
import dj_database_url


dj_database_url
stiamo importando n database postgres da herku e ci sono coinvolti i settings le password username url ecc
quelli cambiano in heroku automanticamente, non posso averceli hard coded

in settings.py alla fine aggiungo
django_heroku.settings(locals())


ora il decoupling della secret key

SECRET_KEY = config("SECRET_KEY")

creo un file .env in cui mi salvo la secret key
SECRET_KEY = 'codicedellachiave'

ora devo dire a git di ignorare quel file, quindi un .gitignore file
i files e cartelle che iniziano con . sono nascoste
nel gitignore file scrivo l'elenco di files . che devono essere ignorati nell'upload, ossia il mio .env

whitenoise thing:
creo cartella static e ci metto dentro un file __init__.py per ora vuoto

ora devo specificare la directory degli static files (in settings)
STATICFILES_DIRS = [
    os.path.join(BASE_DIR, 'static')
]
STATICSTORAGE = "Whitenoise.storage.CompressedManifestStaticFilesStorage"

ora il whitenoise vero e proprio, dentro le installed apps di settings.py
'whitenoise.middleware.WhiteNoiseMiddleware',


procfile

nella directory principale creo un file Procfile senza estensione e ci scrivo dentro
web: gunicorn Metaglossario_Gestisco.wsgi
devi metterci la stessa cosa che trovi in wsgi.py : WSGI config for Metaglossario_Gestisco project.


il procfile mi indica che server viene usato (gunicorn)
se ho fatto bene, il Procfile prende la icona di heroku in vs code

requirements

pip freeze > requirements.txt
devo farlo ogni volta che installo un nuovo modulo, altrimenti heroku potrebbe dirmi che ha dei problemi e indica il collectstatics,
e spesso mi dice anche che non può trovare un modulo, quel modulo va inserito dentor requirements.txt
Nota che requirements prende i moduli installati in generale in python.

git add .
git commit -m "aggiunta app"
git push heroku master


Implementare il database
crea il superuser, ma prima devo fare migrate makemigrate

python manage.py createsuperuser

tommaso
tommaso.sansone@mail.polimi.ti
password


push del codice su heroku
git add .
git commit -m "second commit"
git push heroku master

in questo modo su heroku appare un database postgres che è psycopg2


Nota: ho pushato su heroku e non ho ancora il database

il comando per la diagnostica di cio che non funziona su heroku è 
heroku logs


push del codice su github

github > menu in alto a destra > your repositories > new repository > 
Nome: Metaglossario-Gestisco
<!> non creare readme se no poi fa conflitto e devo usare git pull !!
gitingnore: lascia none

git remote add origin https://github.com/tommasosansone91/Metaglossario-Gestisco.git
git push -u origin master

creo l'app (quella che avrà views, models, urls)
python manage.py startapp app_metaglossario




costruisco il database:
il mio postgres database (psycopg2) è già installato tra gli add ons di heroku
heroku > metaglossario-gestisco > resources > add ons
e l'url del database è stato generato, con al sintassi dell'ultima volta

se vado su post gres database negli addons e ci clicco apre una finestra di dialogo del database corrente
datastores > postgres ...id
se vado sotto settings mi elenca user, password host, ecc
è di questi che si prende cura il dj_database_url


ora se cerco di entrare nell admin dall'app di heroku non va bene il superuser di prima e mi da errore giallo di django
perche prima l'avevo creato in locale, quindi era stato immagazzinato nel database locale, ossia sqlite3,
ora invece devo crearne uno online dove verrà immagazzinato nel postgres database.


heroku run python manage.py migrate

changes applicate

heroku run python manage.py makemigrations
no cambiamenti (ovvio, non c'è il modello!)

esattamente come era avvenuto in locale

heroku run python manage.py createsuperuser

H_admin
tommaso.sansone@mail.polimi.it
password

i due superuser sonbo ancora distinti perchè non ho eseguito l'accoppiamento



 ACCOPPIAMENTO
***************

ora vado di nuovo in datastores di psotgres > settings > db credentials > database_uri
copio uri
la incollo nel default di databases in settings.py, sotto DATABASES

DATABASES['default']=dj_database_url.config(default='postgres://zogpunyhfdizcj:e4e8bbb8ef02572179d0ccdc1a146d4f2eba03e587525349bb4436a80b87f4ec@ec2-46-51-190-87.eu-west-1.compute.amazonaws.com:5432/dfibp7p1uu70v7')

#postgres://user:password@host:porta/database_name
incollare la uri del db in settings.py ci permette che quando runno il server localmente in realtà si connette al cloud di heroku
il locale e il cloud sono sincronizzati

se modifico il database in locale verrà modificato anche in cloud

da questo momento in poi sono condannato a collegarmi col tethering del telefno per runnare il server,
anche in locale, perchè grazie alla chiave si collega in remoto,
posso commentare quella liena per fermare questo effetto

Ma attenzione , perchè la chiave uri che ho incollato per fare la sincronizzazione
cambia day by day su heroku,
quindi non la posso hardcodificare, come ho fatto adesso.

quando la chaive sarà scaduta, posso commentare quella linea e la desincronizzazione mi permette di andare avanti a codificare


COPIO DALLA APP GLOSSARIO TUTTI I FILES
*****************************************

faccio il copia aincolla a mano avendo cura di non sovrascrivere le linee identitarie tipo password ecc
in particolare cambio i settings del database

copio e incollo la cartella templates da app_glossario ad app_metaglossario
copio e incollo il contenuto della cartella static nella directory principale dell metaglossario

Solo il contenuto del database non viene copiato



column app_metaglossario_glossary_entry.Lemma does not exist LINE 1: SELECT
mi dava errore sul glossario.hrml perche non avevo fatto makemigrations migrate dopo aver cambiato nomi alle componenti del modello

a quanto pare l'equivalente di

with open(path) as f:
        reader = csv.reader(f)      

        è

with open(path) as f:
        reader = pd.read_excel(f)
        

+++ ecco cosa c'era nel file Inizializzare

import pandas as pd


# Copia-incollati da
# https://stackoverflow.com/questions/26082128/improperlyconfigured-you-must-either-define-the-environment-variable-django-set/28297987#28297987
from django.conf import settings
settings.configure()

import django
django.setup() 

from app_metaglossario.models import glossary_entry
 


path=r"D:\Files Tommaso\Politecnico\Lavoro polimi\Algoritmi metaglossario Python\traformazioni di prova per il Metaglossario\dati_prova.xlsx"
 
with open(path) as f:
        reader = pd.read_excel(f)
        next(reader, None)  # skip the headers

        for row in reader:
                _, created = glossary_entry.objects.get_or_create(
                Lemma=row[0],
                Acronimo=row[1],
                Definizione=row[2],
                Ambito_riferimento=row[3],
                Autore_definizione=row[4],
                Posizione_definizione=row[5],
                Url_definizione=row[6],
                Titolo_documento_fonte=row[7],
                Autore_documento_fonte=row[8],
                Host_documento_fonte=row[9],
                Url_documento_fonte=row[10],
                Commento_entry=row[11],
                Data_inserimento_entry=row[12],
                Id_statico_entry=row[13],
                )
            # creates a tuple of the new object or
            # current object and a boolean of if it was created

+++++

la seconda versione ho fatto



# myapp/management/commands/import_csv.py
from django.core.management.base import BaseCommand, CommandError
import csv


# il path mi arriva da fuori come input da command line

csv_file=r"D:\Files Tommaso\Politecnico\Lavoro polimi\Algoritmi metaglossario Python\traformazioni di prova per il Metaglossario\dati_prova.csv"

class Command(BaseCommand):

    def add_arguments(self, parser):
        parser.add_argument('csv_file', nargs='+', type=str)

    def handle(self, *args, **options):
        for csv_file in options['csv_file']:
            dataReader = csv.reader(open(csv_file), delimiter=',', quotechar='"')
            for row in dataReader:
                glo=glossary_entry()
                glo.Lemma=row[0],
                Acronimo=row[1],
                Definizione=row[2],
                Ambito_riferimento=row[3],
                Autore_definizione=row[4],
                Posizione_definizione=row[5],
                Url_definizione=row[6],
                Titolo_documento_fonte=row[7],
                Autore_documento_fonte=row[8],
                Host_documento_fonte=row[9],
                Url_documento_fonte=row[10],
                Commento_entry=row[11],
                Data_inserimento_entry=row[12],
                Id_statico_entry=row[13],
                
                # etc...
                self.stdout.write(
                    'Created glossary entry'
                #     'Created glossary entry {} {}'.format(emp.Lemma, emp.Id_statico_entry)
                )

# You would then call this with:
# ./manage.py import_csv --csvfile "/home/<name>/webapps/<name2>/employees.csv"


#       python ./manage.py load_glossary csv_file "D:\Files Tommaso\Politecnico\Lavoro polimi\Algoritmi metaglossario Python\traformazioni di prova per il Metaglossario\dati_prova.csv"


++++++++


conda:

pip install django import-export

settings.py:

    INSTALLED_APPS = [
        'import_export',

admin.py:

from django.contrib import admin
from .models import glossary_entry 

from import_export import resources
from import_export.admin import ImportExportModelAdmin


class glossary_entry_resource(resources.ModelResource):
    class Meta:
        model=glossary_entry

class glossary_entry_Admin(ImportExportModelAdmin, admin.ModelAdmin):
    #resource_class = glossary_entry_resource
    pass


# Register your models here.
admin.site.register(glossary_entry, glossary_entry_Admin)

****

l'importazione da CSV è fallimentare, per importare dati usa i files xlsx

***

                        <p>
                        {% if entry.Url_definizione and entry.Url_definizione != "MISSING"  %}  
                            <a href="{{ entry.Url_definizione }}" Target= "_blank" class="btn btn-primary">Definizione</a> &nbsp                     
                        {% endif %}
                        </p>
                        
                        
                        <p>               
                        {% if entry.Url_documento_fonte and entry.Url_documento_fonte != "MISSING" %}  
                            <a href="{{ entry.Url_documento_fonte }}" Target= "_blank" class="btn btn-primary">Documento fonte</a> &nbsp                   
                        {% endif %}                                  
                        </p>

Ne faccio a meno perchè è problematico. meglio eliminare i missing prima di inserire i fogli. 
Il database di django è molto meglio per gestire i dati mancanti piuttosto che dargli un nome ap priori e fare mille speculazioni su cosa fare

oscurati per praticità i pulsanti url


l'errore a questa linea
 <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

è colpa di un url tag chiuso male in seguito

href="{% url 'home' %}"
va a prendere l'url mappato e riferito al template home, appellativo di home.html

href={% static "css/searchbar_style.css" %}
va a prendere il file al percorso inicato, nella cartella static, 
appellativo che ho dato alla cartella static(il nome dato a stati è specificato in settings.py)

ho cambiato il form della terminologia in modo da nascondere la data

        <div class="form-group">
              <!-- <label for="glossary_entry_input_13">Data di inserimento della terminologia</label>
              <small id="inputHelp" class="form-text text-muted">Compilare solo se è nota la data di pubblicazione del documento fonte, altrimenti inserire la data di oggi.</small>-->
               <input name="Data_inserimento_entry" type="hidden" class="form-control" id="date_to_turn_into_toda">              
        </div>

ma rimane il javascript

<script type="text/javascript" src={% static "js/get_today_date.js" %}></script>
<script> get_today_date() </script> 

fare le ombre in css
  .form-group input:hover{
    
    /* border-color: red; */
    box-shadow: 0 0 10px #ced4da;
    

    
  }

  
  *******


  https://django.readthedocs.io/en/2.2.x/topics/http/file-uploads.html

  registrato il nuovo modello nell'admin

  MEDIA_ROOT e MEDIA_URL sono variabili i cui nomi non possono essere cambiati a piacimento e vanno utilizzati per indicare url e directory dei file salvati



  *****

  TemplateSyntaxError at /carica_glossario
Invalid block tag on line 89: 'static', expected 'endblock'. Did you forget to register or load this tag?

*******

vuol dire che stai mettendo javascipt o css prima del  tag {% load static %}

****

SE MODIFICO L'ID NEL TEMPLATE NON FUNZIONA,
SE MODIFICO L'ID NELLA FUNZIONE FUNZIONA, PERCHè?

l'ho corretto cambiando tutto:
file js, funzione e id nell'input del template

            <div class="form-group">
                <!-- <label for="glossary_entry_input_13">Data di inserimento della terminologia</label>
                <small id="inputHelp" class="form-text text-muted">Compilare solo se è nota la data di pubblicazione del documento fonte, altrimenti inserire la data di oggi.</small>-->
                 <input name="Data_inserimento_glossary" type="hidden" class="form-control" id="mettici_data_di_oggi">              
            </div>


<!-- Javascript -->
<script type="text/javascript" src={% static "js/data_oggi.js" %}> </script> 
<script> attualizza_data_di_ID("mettici_data_di_oggi") </script> 

<!-- static/js/data_oggi.js -->
function attualizza_data_di_ID(id_data) {
    var now = new Date();
    var day = ("0" + now.getDate()).slice(-2);
    var month = ("0" + (now.getMonth() + 1)).slice(-2);
    var today = now.getFullYear()+"-"+(month)+"-"+(day);
    document.getElementById(id_data).value = today;
    }


    ****

    home e aggiungi terminologia hanno lo stesso layout
    glossario e aggiungi glossario hanno lo stesso

    caricament glossario risolto: c era un mismatch tra nome file salvato temlate e nome form+modello

    template:

        <form method="POST" action="" enctype="multipart/form-data" >
        {% csrf_token %}

        <div class="file-upload-wrapper" id="input-file-now">

            <small id="inputHelp" class="form-text text-muted">Seleziona il template compilato con la terminologia da caricare. <br>Non sono accettati i file maggiori di 5M.</small>                  
            <input type="file"  name="Glossary_file" id="input-file-now" data-max-file-size="5M" class="file-upload">
            
            <br><br> 

            <!-- entry della data è nascosto -->
            <!-- in futuro posso rendere da forms.py il fatto che html non devono essere presi certi campi, quindi al posto di nasconderli tolgo proprio l'input. però devo far sì che nel modello si generino da soli se non specificati dall'utente -->
            <div class="form-group">
                <!-- <label for="glossary_entry_input_13">Data di inserimento della terminologia</label>
                <small id="inputHelp" class="form-text text-muted">Compilare solo se è nota la data di pubblicazione del documento fonte, altrimenti inserire la data di oggi.</small>-->
                 <input name="Data_inserimento_glossary" type="hidden" class="form-control" id="mettici_data_di_oggi">              
            </div>
            <!-- la data funziona - ho controllato -->
  
            <div class="container">
                <button type="submit" class="btn btn-primary">Carica glossario</button>
            </div>
        </div>

    </form>

forms.py:

    class glossary_file_form(forms.ModelForm):

    class Meta:
        model = glossary_file
        fields = ["Glossary_file", "Data_inserimento_glossary"]

models.py:

class glossary_file(models.Model):

    Glossary_file = models.FileField(upload_to='uploaded_glossaries/', blank=False, null=False)

    Data_inserimento_glossary = models.DateField(blank=False, null=False, default=timezone.now().date() )
    # Data_inserimento_entry = models.DateField(blank=False, null=False, default=timezone.now().date)


    class Meta:
        ordering = ['Data_inserimento_glossary', 'Glossary_file']
        # il meno davanti all'attributo vuol dire che ordina al contrario
        # '-Admin_approval_switch', 
        # faccio comparire per primi gli hide-> nuovi inseriti
        # in realtà per come ho definito hide e show, se metto senza il meno davanti, mi mostra per prima hide (h viene prima di s)

    def clean(self):
        if not (self.Glossary_file or self.Data_inserimento_glossary):
            raise ValidationError("Non è stato selezionato alcun glossario per il caricamento.")
        # non mi restituisce questa scritta ma quella messa di default nelle views

    def __str__(self):    
        # print("%s is %d years old." % (name, age))    
        return  "%s ----- [%s]"  %  (self.Glossary_file, self.Data_inserimento_glossary)  
        #quello che fa apparire nella sezione admin, attributo che riassume tutti gli altri, quindi una primary key presumibilmente, pouò anche esesere la combinazione degli altri

views.py:

def aggiungi_glossario(request):

    #se si esegue il POST (click del pulsante submit)
    if request.method=='POST': 

        form = glossary_file_form(request.POST or None, request.FILES or None)
        # form = glossary_file_form(request.POST, request.FILES)

        if form.is_valid():
            form.save()
            insert_attempt_output="corretto"
            # insert_attempt_output formatta il colore del messaggio, vedi in base.html
            messages.success(request, ("Glossario inserito con successo!\nAttendere la convalida da parte dell\'amministratore.\n Per favore non inserire di nuovo la stessa terminologia"))
            return redirect('aggiungi_glossario')

        else:
            insert_attempt_output="errato"
            messages.error(request, ('ERRORE: Non è stato caricato alcun glossario.'))
            return render(request, 'aggiungi_glossario.html', {'insert_attempt_output':insert_attempt_output})
    
    # se si va sulla pagina e basta
    else:   
        return render(request, 'aggiungi_glossario.html', {}) 

cambiato percosto internet di aggiungi glossario in aggiungi terminologia massa

prima della modificato
def glossario(request):

    query = request.GET.get('q') #q è variabile risultante dalla query del database
    template = "glossario.html" #il template è sempre lo stesso

    # se la query è stata fatta
    if query:
        
        query = request.GET.get('q') #q è variabile risultante dalla query del database
        selected_entries = glossary_entry.objects.filter(Q(Acronimo__icontains=query)|Q(Ambito_riferimento__icontains=query)|Q(Autore_definizione__icontains=query)|Q(Autore_documento_fonte__icontains=query)|Q(Data_inserimento_entry__icontains=query)|Q(Definizione__icontains=query)|Q(Host_documento_fonte__icontains=query)|Q(Id_statico_entry__icontains=query)|Q(Lemma__icontains=query)|Q(Posizione_definizione__icontains=query)|Q(Titolo_documento_fonte__icontains=query)|Q(Url_definizione__icontains=query)|Q(Url_documento_fonte__icontains=query))
        
        
        # context = {'all_entries':selected_entries}
        #return render(request, template, context)
        return render(request, template, {'all_entries':selected_entries})

    # se non è stata fatta nessuna query
    else:

        all_entries = glossary_entry.objects.all #funziona lo stesso anche se dice Class 'glossary_entry' has no 'objects' memberpylint(no-member)
        return render(request, template, {'all_entries':all_entries})

****

TypeError at /glossario
object of type 'method' has no len() 

probabile errore nel template

riolto mettendo aggiungendo () in views alla linea

all_entries = glossary_entry.objects.all()

per qualche motivo mi dava errore qui 

all_entries = paginator.get_page(page) 

*****

se al paginator ne aggiungo altri in costruzione mi da errore empty page perchè ho il template che contiene i djajngo tags e lo manda in palla


****

il mio paginatore:

<nav aria-label="...">
            <ul class="pagination">

                {% if all_entries.has_previous %}

                <li class="page-item">
                    <a class="page-link" href="?page=1">&laquo; first</a> 
                </li>
                    
                <li class="page-item">
                    <a class="page-link" href="?page={{ all_entries.previous_page_number }}">{{ all_entries.previous_page_number }}</a>
                </li>

                {% else %}

                <li class="page-item disabled">
                    <a class="page-link" href="#" class="page-item disabled">&laquo; first</a>  
                </li> 
                
                <!-- <li class="page-item disabled"></li>
                    <a class="page-link" href="#" class="page-item disabled">previous</a>
                </li> -->

                {% endif %}



                <li class="page-item active">
                <a class="page-link" href="#">{{ all_entries.number }}<span class="sr-only">(current)</span></a>
                </li>



                {% if all_entries.has_next %}
                    
                <li class="page-item">
                    <a class="page-link" href="?page={{ all_entries.next_page_number }}">{{ all_entries.next_page_number }}</a>
                </li>

                <li class="page-item">
                    <a class="page-link" href="?page={{ all_entries.paginator.num_pages }}">Last &raquo;</a> 
                </li>

                {% else %}
                               
                <!-- <li class="page-item disabled"></li>
                    <a class="page-link" href="#" class="page-item disabled">next</a>
                </li> -->

                <li class="page-item disabled">
                   <a class="page-link" href="#" class="page-item disabled">Last &raquo;</a>  
                </li> 
                
                {% endif %}

            </ul>
        </nav>

questo l'avevo implementato ma non funziona:

# per ora non funziona

# myapp/management/commands/load_glossary.py
from django.core.management.base import BaseCommand, CommandError
import csv

class Command(BaseCommand):

    def add_arguments(self, parser):
        parser.add_argument('csv_file', nargs='+', type=str)

    def handle(self, *args, **options):
        for csv_file in options['csv_file']:
            dataReader = csv.reader(open(csv_file), delimiter=',', quotechar='"')
            for row in dataReader:
                
                Lemma=row[0],
                Acronimo=row[1],
                Definizione=row[2],
                Ambito_riferimento=row[3],
                Autore_definizione=row[4],
                Posizione_definizione=row[5],
                Url_definizione=row[6],
                Titolo_documento_fonte=row[7],
                Autore_documento_fonte=row[8],
                Host_documento_fonte=row[9],
                Url_documento_fonte=row[10],
                Commento_entry=row[11],
                Data_inserimento_entry=row[12],
                Id_statico_entry=row[13],
                
                # etc...
                self.stdout.write(
                    'Created glossary entry'
                #     'Created glossary entry {} {}'.format(emp.Lemma, emp.Id_statico_entry)
                )

# You would then call this with:
# ./manage.py import_csv --csvfile "/home/<name>/webapps/<name2>/employees.csv"


#       python ./manage.py load_glossary csv_file "D:\Files Tommaso\Politecnico\Lavoro polimi\Algoritmi metaglossario Python\traformazioni di prova per il Metaglossario\dati_prova.csv"

************************************

django admin import export,
problemi di importazione potrebbero essere legati alla lunghezza massima dei campi nel modello
servono circa 25 secondi per importare 70 record. con import export da admin

***

creo i filters per combinare filtri e paginazione

****

def glossario(request):

    query = request.GET.get('q') #q è variabile risultante dalla query del database
    # non sostuituirla col valore vuoto

    template = "glossario.html" #il template è sempre lo stesso

    all_entries = glossary_entry.objects.all() #funziona lo stesso anche se dice Class 'glossary_entry' has no 'objects' memberpylint(no-member)
    
    # se la query è stata fatta
    if query:
        
        query = request.GET.get('q') #q è variabile risultante dalla query del database

        selected_entries = filters.glossary_entry_filter(request.GET, queryset=glossary_entry.objects.all()).qs
        # Q(Acronimo__icontains=query dice quali sono i campi in cui cercare l'input specificato dall'utente
        
        # Pagination        
        paginator = Paginator(selected_entries, 10) # Show 25 contacts per page
        page = request.GET.get('page')

        try:
            response = paginator.page(page)
        except PageNotAnInteger:
            response = paginator.page(1)
        except EmptyPage:
            response = paginator.page(paginator.num_pages)
        
        # context = {'all_entries':selected_entries}
        #return render(request, template, context)
        # {'nome della variabile con cui sarà richiamato nel template':contenuto}
        return render(request, template, {'all_entries':response})

    # se non è stata fatta nessuna query
    else:

        # Pagination
        paginator = Paginator(all_entries, 10) # Show 25 contacts per page
        page = request.GET.get('page')
        all_entries = paginator.get_page(page)

        return render(request, template, {'all_entries':all_entries})


        errato non funzione

        ***********


fixato così:

paginator nel template:

        <nav aria-label="...">
            <ul class="pagination">

                
                                
                {% if all_entries.has_previous %}
                
                <li class="page-item">
                    <a class="page-link" href="?page=1&q={{ query }}">&laquo; Prima pagina</a> 
                </li>
                    
                <li class="page-item">
                    <a class="page-link" href="?page={{ all_entries.previous_page_number }}&q={{ query }}">{{ all_entries.previous_page_number }}</a>
                </li>

                {% else %}

                <li class="page-item disabled">
                    <a class="page-link" href="#" class="page-item disabled">&laquo; Prima pagina</a>  
                </li> 
                
                <!-- <li class="page-item disabled"></li>
                    <a class="page-link" href="#" class="page-item disabled">previous</a>
                </li> -->

                {% endif %}



                <li class="page-item active">
                <a class="page-link" href="#">{{ all_entries.number }}<span class="sr-only">(current)</span></a>
                </li>



                {% if all_entries.has_next %}
                    
                <li class="page-item">
                    <a class="page-link" href="?page={{ all_entries.next_page_number }}&q={{ query }}">{{ all_entries.next_page_number }}</a>
                </li>

                <li class="page-item">
                    <a class="page-link" href="?page={{ all_entries.paginator.num_pages }}&q={{ query }}">Ultima pagina [ {{ all_entries.paginator.num_pages }} ] &raquo;</a> 
                </li>

                {% else %}
                               
                <!-- <li class="page-item disabled"></li>
                    <a class="page-link" href="#" class="page-item disabled">next</a>
                </li> -->

                <li class="page-item disabled">
                   <a class="page-link" href="#" class="page-item disabled">Ultima pagina [ {{ all_entries.paginator.num_pages }} ] &raquo;</a>  
                </li> 
                
                {% endif %}

            </ul>
        </nav>

views.py

def glossario(request):

    query = request.GET.get('q') #q è variabile risultante dalla query del database
    # non sostuituirla col valore vuoto

    template = "glossario.html" #il template è sempre lo stesso

    all_entries = glossary_entry.objects.all() #funziona lo stesso anche se dice Class 'glossary_entry' has no 'objects' memberpylint(no-member)
    
    # se la query è stata fatta
    if query:
        
        query = request.GET.get('q') #q è variabile risultante dalla query del database
        selected_entries = glossary_entry.objects.filter(Q(Acronimo__icontains=query)|Q(Ambito_riferimento__icontains=query)|Q(Autore_definizione__icontains=query)|Q(Autore_documento_fonte__icontains=query)|Q(Data_inserimento_entry__icontains=query)|Q(Definizione__icontains=query)|Q(Host_documento_fonte__icontains=query)|Q(Id_statico_entry__icontains=query)|Q(Lemma__icontains=query)|Q(Posizione_definizione__icontains=query)|Q(Titolo_documento_fonte__icontains=query)|Q(Url_definizione__icontains=query)|Q(Url_documento_fonte__icontains=query))
        # Q(Acronimo__icontains=query dice quali sono i campi in cui cercare l'input specificato dall'utente
        
        # Pagination        
        paginator = Paginator(selected_entries, 10) # Show 25 contacts per page
        page = request.GET.get('page')
        selected_entries = paginator.get_page(page)
        
        # context = {'all_entries':selected_entries}
        #return render(request, template, context)
        # {'nome della variabile con cui sarà richiamato nel template':contenuto}
        return render(request, template, {'all_entries':selected_entries, 'query':query})

    # se non è stata fatta nessuna query
    else:

        # Pagination
        paginator = Paginator(all_entries, 10) # Show 25 contacts per page
        page = request.GET.get('page')
        all_entries = paginator.get_page(page)

        return render(request, template, {'all_entries':all_entries, 'query':query})


*****


paginatore mNUALE


        <!-- navigatore di paginazione manuale -->
        
        {% if query %}

        <form method="GET" >
                <nav aria-label="...">
                    <ul class="pagination">
                    
                    <li class="page-item disabled"><a class="page-link" >Vai alla pagina: </a></li>
                    <li class="hidden"><input type="hidden" name="q" value="{{request.GET.q}}"></li>
                    <li class="page-item"><input style="width: 60px; color:grey" class="page-link" name="page"></li>                    
                    <li class="page-item">&nbsp&nbsp&nbsp<button type="submit" class="btn btn-primary" href="?q={{query}}&page={{page}}">Vai</button></li>
                    </ul>
                    
                </nav>
            </form>

        {% else %}

        <!-- se la query è vuota questo funziona -->

        <form method="GET" action="{% url 'glossario' %}">
                <nav aria-label="...">
                    <ul class="pagination">
                    
                    <li class="page-item disabled"><a class="page-link" >Vai alla pagina: </a></li>
                    <li class="page-item" ><input style="width: 60px; color:grey" class="page-link" name="page" value=""></li>
                    <li class="page-item">&nbsp&nbsp&nbsp<button type="submit" class="btn btn-primary">Vai</button></li>
                    </ul>
                    
                </nav>
            </form>

            
        {% endif %}


IN REALTà BASTA ANCHE DA SOLO questo

<!-- navigatore di paginazione manuale -->

        <form method="GET" >
                <nav aria-label="...">
                    <ul class="pagination">
                    
                    <li class="page-item disabled"><a class="page-link" >Vai alla pagina: </a></li>
                    <li class="hidden"><input type="hidden" name="q" value="{{request.GET.q}}"></li>
                    <li class="page-item"><input style="width: 60px; color:grey" class="page-link" name="page"></li>                    
                    <li class="page-item">&nbsp&nbsp&nbsp<button type="submit" class="btn btn-primary" href="?q={{query}}&page={{page}}">Vai</button></li>
                    </ul>
                    
                </nav>
            </form>


Il dizionario mi permette di passare le variabili dalla views.py al template



/* è il rettangolone fuori */
  #navigation_box { 
    background-color: #e9e9e9;
    border: 1px;
    /* border-radius: 4px; */
    padding:20px;
  }


/* regola i pulsanti attivabili della parte di sopra del navigatore */
.pagination a {
  color: black;
  background-color: #ddd;
  border-color: #ddd;
}


/* regola lo hover dei pulsanti attivabili della parte di sopra del navigatore */
  .pagination a:hover {
    color: white;
    background-color: #007bff;
    border-color: #007bff;
  }

  .pagination input {
    background-color: #f8f8f8;   

  }

  .pagination input:hover {
    background-color: white;
    /* mettere borders 2 px qui dentro faceva saltare la linea successiva */
    border-color: #007bffc4;

  }


  .page-item button{
    transition: 0s background-color;
    background-color: #ddd;
    color: black;
    border-color: #ddd;
  }

  #active_page_sign{
    border-color: rgb(165, 165, 165);
    background-color: rgb(165, 165, 165);
  }
/* 
  #tasto_navigazione_pagina_cliccabile{

    color:

  } */

#tasto_navigazione_pagina_disabilitato{
  color:white;
  border-color: rgb(165, 165, 165);
  background-color: rgb(165, 165, 165);
}

#vai_alla_pagina_disabilitato{

  background-color: #ddd;
  color: black;
  border-color: #ddd;
}

*****

in settings.py
DATA_UPLOAD_MAX_NUMBER_FIELDS = 10240 # higher than the count of fields

path('api/api_glossario', views.api_glossario, name="api_glossario")

***

ricordati sempe di registrare i nuovi modelli nella sezione admin per farli comparire


def pour_entire_file_model():

    print("Inizia il riversamento di dati dal modello glossary_file al modello acquired_terminology!")

    import pandas as pd
    import xlrd
    from xlrd import open_workbook

    from .models import glossary_file, acquired_terminology

    # tutti gli oggetti nel modello glossario sono salvati qui
    all_files = glossary_file.objects.all()

    # print(all_files)

    for file_element in all_files: 
   
        # per ogni foglio nel modello
        print("Inizia la lettura del foglio %s per estrarne la terminologia riga per riga!" % file_element.Glossary_file)
        

        # salva le cose nel foglio

        workbook = pd.read_excel(file_element.Glossary_file)

        print(workbook)


        alt+z a capo automatico in vs xstudio

****

def pour_entire_simple_model():

    print("Inizia il riversamento di dati dal modello glossary_entry al modello acquired_terminology!")

    from .models import glossary_entry, acquired_terminology
    all_entries = glossary_entry.objects.all()

    # for element in all_entries[:10]:
    #     print(element.Lemma)
        
    for element in all_entries:
        acquired_terminology.objects.create(Lemma=element.Lemma, Acronimo=element.Acronimo, Definizione=element.Definizione, Ambito_riferimento=element.Ambito_riferimento, Autore_definizione=element.Autore_definizione, Posizione_definizione=element.Posizione_definizione, Url_definizione=element.Url_definizione, Titolo_documento_fonte=element.Titolo_documento_fonte, Autore_documento_fonte=element.Autore_documento_fonte, Host_documento_fonte=element.Host_documento_fonte, Url_documento_fonte=element.Url_documento_fonte, Commento_entry=element.Commento_entry, Data_inserimento_entry=element.Data_inserimento_entry, Id_statico_entry=element.Id_statico_entry, Admin_approval_switch=element.Admin_approval_switch)

    print("Riversamento terminato con successo!")




def pour_entire_file_model():

    print("Inizia il riversamento della terminologia di tutti i file salvati nel modello glossary_file al modello acquired_terminology...")

    import pandas as pd
    from .models import glossary_file, acquired_terminology

    # tutti gli oggetti nel modello glossario sono salvati qui
    all_files = glossary_file.objects.all()
    
    for file_element in all_files: 
   
        # per ogni foglio nel modello
        print("Inizia la lettura del foglio %s per estrarne la terminologia riga per riga..." % file_element.Glossary_file)
        
        # accedo all'attributo file del modello
        # salva il contenuto del file in una variabile = dataframe
        excel_sheet = pd.read_excel(file_element.Glossary_file)

        print("*****") 
        print(excel_sheet)
        print("*****")       

        print("Sbobinatura del dataframe in vettori...")

        
        
        col_lemma = excel_sheet.Lemma
        col_acronimo = excel_sheet.Acronimo
        col_definizione = excel_sheet.Definizione
        col_ambiti_riferimento = excel_sheet.Ambito_riferimento
        col_autore_definizione = excel_sheet.Autore_definizione
        col_posizione_definizione = excel_sheet.Posizione_definizione
        col_url_definizione = excel_sheet.Url_definizione
        col_titolo_documento_fonte = excel_sheet.Titolo_documento_fonte
        col_autore_documento_fonte = excel_sheet.Autore_documento_fonte
        col_host_documento_fonte = excel_sheet.Host_documento_fonte
        col_url_documento_fonte = excel_sheet.Url_documento_fonte
        col_commento_entry = excel_sheet.Commento_entry
        col_data_inserimento_entry = excel_sheet.Data_inserimento_entry
        col_id_statico_entry = excel_sheet.Id_statico_entry
        col_admin_approval_switch = excel_sheet.Admin_approval_switch

        print("Inizia il riversamento di dati dal foglio al modello acquired_terminology!")

        for i in range(len(col_lemma)):

        # assegna i valori agli attributi uno per uno per evitare i NaN
            
        
        



            acquired_terminology.objects.create(Lemma=col_lemma[i], Acronimo=col_acronimo[i], Definizione=col_definizione[i], Ambito_riferimento=col_ambiti_riferimento[i], Autore_definizione=col_autore_definizione[i], Posizione_definizione=col_posizione_definizione[i], Url_definizione=col_url_definizione[i], Titolo_documento_fonte=col_titolo_documento_fonte[i], Autore_documento_fonte=col_autore_documento_fonte[i], Host_documento_fonte=col_host_documento_fonte[i], Url_documento_fonte=col_url_documento_fonte[i], Commento_entry=col_commento_entry[i], Data_inserimento_entry=col_data_inserimento_entry[i], Id_statico_entry=col_id_statico_entry[i], Admin_approval_switch=col_admin_approval_switch[i])

        print("Riversamento dei dati in %s terminato con successo!" % file_element.Glossary_file)
        print("*****")
    
        
    print("La terminologia di tutti i file salvati nel modello glossary_file è stata riversata nel modello acquired_terminology!")


************


def pour_entire_file_model():

    print("Inizia il riversamento della terminologia di tutti i file salvati nel modello glossary_file al modello acquired_terminology...")

    import pandas as pd
    
    from .models import glossary_file, acquired_terminology

    # tutti gli oggetti nel modello glossario sono salvati qui
    all_files = glossary_file.objects.all()
    
    for file_element in all_files: 
   
        # per ogni foglio nel modello
        print("Inizia la lettura del foglio %s per estrarne la terminologia riga per riga..." % file_element.Glossary_file)
        
        # accedo all'attributo file del modello
        # salva il contenuto del file in una variabile = dataframe
        excel_sheet = pd.read_excel(file_element.Glossary_file)

        print("*****") 
        print(excel_sheet)
        print("*****")       

        print("Sbobinatura del dataframe in vettori...")

        
        
        col_lemma = excel_sheet.Lemma
        col_acronimo = excel_sheet.Acronimo
        col_definizione = excel_sheet.Definizione
        col_ambiti_riferimento = excel_sheet.Ambito_riferimento
        col_autore_definizione = excel_sheet.Autore_definizione
        col_posizione_definizione = excel_sheet.Posizione_definizione
        col_url_definizione = excel_sheet.Url_definizione
        col_titolo_documento_fonte = excel_sheet.Titolo_documento_fonte
        col_autore_documento_fonte = excel_sheet.Autore_documento_fonte
        col_host_documento_fonte = excel_sheet.Host_documento_fonte
        col_url_documento_fonte = excel_sheet.Url_documento_fonte
        col_commento_entry = excel_sheet.Commento_entry
        col_data_inserimento_entry = excel_sheet.Data_inserimento_entry
        col_id_statico_entry = excel_sheet.Id_statico_entry
        col_admin_approval_switch = excel_sheet.Admin_approval_switch

        print("Inizia il riversamento di dati dal foglio al modello acquired_terminology!")

        for i in range(len(col_lemma)):

        # assegna i valori agli attributi uno per uno per evitare i NaN
            
            entry = acquired_terminology.objects.create()
            
            if not pd.isnull(col_lemma[i]):
                entry.Lemma=col_lemma[i]

            if not pd.isnull(col_acronimo[i]):
                entry.Acronimo=col_acronimo[i]

            if not pd.isnull(col_definizione[i]):    
                entry.Definizione=col_definizione[i]

            if not pd.isnull(col_ambiti_riferimento[i]):    
                entry.Ambito_riferimento=col_ambiti_riferimento[i]

            if not pd.isnull(col_autore_definizione[i]):    
                entry.Autore_definizione=col_autore_definizione[i]

            if not pd.isnull(col_posizione_definizione[i]):    
                entry.Posizione_definizione=col_posizione_definizione[i]

            if not pd.isnull(col_url_definizione[i]):    
                entry.Url_definizione=col_url_definizione[i]

            if not pd.isnull(col_titolo_documento_fonte[i]):    
                entry.Titolo_documento_fonte=col_titolo_documento_fonte[i]

            if not pd.isnull(col_autore_documento_fonte[i]):    
                entry.Autore_documento_fonte=col_autore_documento_fonte[i]

            if not pd.isnull(col_host_documento_fonte[i]):    
                entry.Host_documento_fonte=col_host_documento_fonte[i]

            if not pd.isnull(col_url_documento_fonte[i]):    
                entry.Url_documento_fonte=col_url_documento_fonte[i]

            if not pd.isnull(col_commento_entry[i]):    
                entry.Commento_entry=col_commento_entry[i]

                
            entry.Data_inserimento_entry=col_data_inserimento_entry[i]
            entry.Id_statico_entry=col_id_statico_entry[i]               
            entry.Admin_approval_switch=col_admin_approval_switch[i]

            entry.save()


        print("Riversamento dei dati in %s terminato con successo!" % file_element.Glossary_file)
        print("*****")
    
        
    print("La terminologia di tutti i file salvati nel modello glossary_file è stata riversata nel modello acquired_terminology!")

    *****
 § sostituito con acquired terminology************

    def glossario(request):

    
    # erase_union_model()
    # pour_entire_simple_model()
    # pour_entire_file_model()

    query = request.GET.get('q') #q è variabile risultante dalla query del database
    # non sostuituirla col valore vuoto

    template = "glossario.html" #il template è sempre lo stesso

    all_entries = acquired_terminology.objects.all() #funziona lo stesso anche se dice Class 'glossary_entry' has no 'objects' memberpylint(no-member)

    # se la query è stata fatta
    if query:

        query = request.GET.get('q') #q è variabile risultante dalla query del database

        selected_entries = acquired_terminology.objects.filter(Q(Acronimo__icontains=query)|Q(Ambito_riferimento__icontains=query)|Q(Autore_definizione__icontains=query)|Q(Autore_documento_fonte__icontains=query)|Q(Data_inserimento_entry__icontains=query)|Q(Definizione__icontains=query)|Q(Host_documento_fonte__icontains=query)|Q(Id_statico_entry__icontains=query)|Q(Lemma__icontains=query)|Q(Posizione_definizione__icontains=query)|Q(Titolo_documento_fonte__icontains=query)|Q(Url_definizione__icontains=query)|Q(Url_documento_fonte__icontains=query))
        # Q(Acronimo__icontains=query dice quali sono i campi in cui cercare l'input specificato dall'utente

        # Pagination
        paginator = Paginator(selected_entries, 10) # Show 25 contacts per page
        page = request.GET.get('page')
        selected_entries = paginator.get_page(page)

        # context = {'all_entries':selected_entries}
        #return render(request, template, context)
        # {'nome della variabile con cui sarà richiamato nel template':contenuto}
        return render(request, template, {'all_entries':selected_entries, 'query':query})

    # se non è stata fatta nessuna query
    else:

        # Pagination
        paginator = Paginator(all_entries, 10) # Show 25 contacts per page
        page = request.GET.get('page')
        all_entries = paginator.get_page(page)

        return render(request, template, {'all_entries':all_entries, 'query':query})


# QUESTA è LA SINGOLA ENTRY
def aggiungi_terminologia(request):

    #se si esegue il POST (click del pulsante submit)
    if request.method=='POST':
        form = glossary_entry_form(request.POST or None)

        # request.POST è il contenuto inserito dagli utenti perchè request è il paramentro in ingresso della funzione

        if form.is_valid(): # funzione che controlla la coerenza dei campi (mail, url, numerico, testo, ecc.)
            form.save()
            insert_attempt_output="corretto"
            # insert_attempt_output formatta il colore del messaggio, vedi in base.html
            messages.success(request, ("Terminologia inserita con successo!\nAttendere la convalida da parte dell\'amministratore.\n Per favore non inserire di nuovo la stessa terminologia"))
            return redirect('aggiungi_terminologia')
            # con redirect non posso usare .html, ma per forza names

        else:
            insert_attempt_output="errato"
            messages.error(request, ('ERRORE: La terminologia non è stata inserita nel glossario.\nCompilare almeno un campo e la data di inserimento.'))
            return render(request, 'aggiungi_terminologia.html', {'insert_attempt_output':insert_attempt_output})

    # se si va sulla pagina e basta
    else:
        return render(request, 'aggiungi_terminologia.html', {})


Ho sistemato il problema del server dati in eccesso heroku facendo:

elimina dati da dashboard di heroku (non distruggere il database)
quindi makemigrations, migrate
git add .
git commit -m "qualcosa"
git push heroku master
heroku run python manage.py createsuperuser

quando ho più file con lo stesso nome nel database, uno viene rinominato e django fallisce.
per ora risolvo eliminando i files duplicati di nome in locale.

https://realpython.com/absolute-vs-relative-python-imports/


def pour_entire__my_file_model():

    import pandas as pd
    from .models import my_file_model, output_model
    all_files = my_file_model.objects.all()

    for file_element in all_files: 

        excel_sheet = pd.read_excel(file_element.My_file_model)
        var_col_A = excel_sheet.Column_A
        var_col_B = excel_sheet.Column_B
        var_col_C = excel_sheet.Column_C

        for i in range(len(var_col_A)):            
            output_model.objects.create(field_A=var_col_A[i], field_B=var_col_B[i], field_C=var_col_C[i])


***

algoritmo PGI backup


def algoritmo_PGI():

    # algoritmo per standardizzare i dati prima di incatenarli nella struttura relazionale

    import pandas as pd
    from app_metaglossario.models import acquired_terminology, prepared_terminology

    print("Inizia la standardizzazione del formato dei dati per prepararli all'inserimento nel database...")
    
    # database di prima elaborazione
    # ppure uso degli spazi virtuali, ossia le variabili, per ogni scrittura

    #  svuoto il database destinazione 

    prepared_terminology.objects.all().delete()

    # lista del vecchio modello
    acquired_rows = acquired_terminology.objects.all()

    print("Il modello prepared_terminology è stato svuotato!")

    print("Inizia lo riempimento del modello prepared_terminology...")

    # compilo il nuovo modello coi dati 

    for element in acquired_rows:

        prepared_entry = prepared_terminology.objects.create()
        
        if not pd.isnull(element.Lemma):
            prepared_entry.Lemma = element.Lemma

        if not pd.isnull(element.Id_statico_entry):
            prepared_entry.Id_statico_entry = element.Id_statico_entry

        if not pd.isnull(element.Definizione):    
            prepared_entry.Definizione = element.Definizione

        if not pd.isnull(element.Ambito_riferimento):    
            prepared_entry.Ambito_riferimento = element.Ambito_riferimento

        if not pd.isnull(element.Autore_definizione):    
            prepared_entry.Autore_definizione = element.Autore_definizione

        if not pd.isnull(element.Posizione_definizione):    
            prepared_entry.Posizione_definizione = element.Posizione_definizione

        if not pd.isnull(element.Url_definizione):    
            prepared_entry.Url_definizione = element.Url_definizione

        if not pd.isnull(element.Titolo_documento_fonte):    
            prepared_entry.Titolo_documento_fonte = element.Titolo_documento_fonte

        if not pd.isnull(element.Autore_documento_fonte):    
            prepared_entry.Autore_documento_fonte = element.Autore_documento_fonte

        if not pd.isnull(element.Host_documento_fonte):    
            prepared_entry.Host_documento_fonte = element.Host_documento_fonte

        if not pd.isnull(element.Url_documento_fonte):    
            prepared_entry.Url_documento_fonte = element.Url_documento_fonte

        if not pd.isnull(element.Commento_entry):    
            prepared_entry.Commento_entry = element.Commento_entry

            
        prepared_entry.Data_inserimento_entry = element.Data_inserimento_entry
        prepared_entry.Id_statico_entry = element.Id_statico_entry               
        prepared_entry.Admin_approval_switch = element.Admin_approval_switch

        prepared_entry.save()


    print("Riempimento del modello prepared_terminology terminato con successo!")

    print("Inizia l'elaborazione della terminologia contenuta nel modello prepared_terminology...")


    # upper, lower, title
    print("Inizia la modifica del formato del testo (uppercase/title)...")

    prepared_rows = prepared_terminology.objects.all()

    for prepared_entry in prepared_rows:

        if not pd.isnull(prepared_entry.Lemma):
            prepared_entry.Lemma.title() # non è veramente necessario

        if not pd.isnull(prepared_entry.Id_statico_entry):
            prepared_entry.Id_statico_entry.upper()
            
        if not pd.isnull(prepared_entry.Ambito_riferimento):    
            prepared_entry.Ambito_riferimento.title() # non è veramente necessario

        if not pd.isnull(prepared_entry.Autore_definizione):    
            prepared_entry.Autore_definizione.title() # non è veramente necessario

        if not pd.isnull(prepared_entry.Posizione_definizione):    
            prepared_entry.Posizione_definizione.title() # non è veramente necessario

        if not pd.isnull(prepared_entry.Titolo_documento_fonte):    
            prepared_entry.Titolo_documento_fonte.title() # non è veramente necessario

        if not pd.isnull(prepared_entry.Autore_documento_fonte):    
            prepared_entry.Autore_documento_fonte.title() # non è veramente necessario

        if not pd.isnull(prepared_entry.Host_documento_fonte):    
            prepared_entry.Host_documento_fonte.title() # non è veramente necessario

        prepared_entry.Id_statico_entry.upper() 

        prepared_entry.save()
        

    

       

    print("Modifica del formato del testo (uppercase/title) terminato con successo!")

    # sostituzione di doppi spazi e  acapo con degli spazi

    print("Inizia l'eliminazione dei doppi spazi dal testo...")
    
    rip_doppi_spazi = 3 # ripeto il ciclo 3 volte 

    prepared_rows = prepared_terminology.objects.all()

    for i in range(rip_doppi_spazi):    # ripeto il ciclo n volte 

        for prepared_entry in prepared_rows:        
            
            if not pd.isnull(prepared_entry.Lemma):
                prepared_entry.Lemma = prepared_entry.Lemma.replace("  ", " ")

            if not pd.isnull(prepared_entry.Id_statico_entry):
                prepared_entry.Id_statico_entry = prepared_entry.Id_statico_entry.replace("  ", " ")

            if not pd.isnull(prepared_entry.Definizione):    
                prepared_entry.Definizione = prepared_entry.Definizione.replace("  ", " ")

            if not pd.isnull(prepared_entry.Ambito_riferimento):    
                prepared_entry.Ambito_riferimento = prepared_entry.Ambito_riferimento.replace("  ", " ")

            if not pd.isnull(prepared_entry.Autore_definizione):    
                prepared_entry.Autore_definizione = prepared_entry.Autore_definizione.replace("  ", " ")

            if not pd.isnull(prepared_entry.Posizione_definizione):    
                prepared_entry.Posizione_definizione = prepared_entry.Posizione_definizione.replace("  ", " ")

            if not pd.isnull(prepared_entry.Titolo_documento_fonte):    
                prepared_entry.Titolo_documento_fonte = prepared_entry.Titolo_documento_fonte.replace("  ", " ")

            if not pd.isnull(prepared_entry.Autore_documento_fonte):    
                prepared_entry.Autore_documento_fonte = prepared_entry.Autore_documento_fonte.replace("  ", " ")

            if not pd.isnull(prepared_entry.Host_documento_fonte):    
                prepared_entry.Host_documento_fonte = prepared_entry.Host_documento_fonte.replace("  ", " ")
            
            if not pd.isnull(prepared_entry.Commento_entry):    
                prepared_entry.Commento_entry = prepared_entry.Commento_entry.replace("  ", " ")                      
        

            prepared_entry.save()

            # elimina spazi da davanti e dietro


    print("Eliminazione dei doppi spazi terminata con successo!")
    print("Inizia l'eliminazione degli spazi all'inizio e alla fine di ogni cella...")

    prepared_rows = prepared_terminology.objects.all()

    for prepared_entry in prepared_rows:        
        
        if not pd.isnull(prepared_entry.Lemma):
            if prepared_entry.Lemma[0] == " ":
                prepared_entry.Lemma = prepared_entry.Lemma[1:]
            if prepared_entry.Lemma[-1] == " ":
                prepared_entry.Lemma = prepared_entry.Lemma[0:-1]

        if not pd.isnull(prepared_entry.Id_statico_entry):
            if prepared_entry.Id_statico_entry[0] == " ":
                prepared_entry.Id_statico_entry = prepared_entry.Id_statico_entry[1:]
            if prepared_entry.Id_statico_entry[-1] == " ":
                prepared_entry.Id_statico_entry = prepared_entry.Id_statico_entry[0:-1]


        if not pd.isnull(prepared_entry.Definizione):    
            if prepared_entry.Definizione[0] == " ":
                prepared_entry.Definizione = prepared_entry.Definizione[1:]
            if prepared_entry.Definizione[-1] == " ":
                prepared_entry.Definizione = prepared_entry.Definizione[0:-1]

        if not pd.isnull(prepared_entry.Ambito_riferimento):    
            if prepared_entry.Ambito_riferimento[0] == " ":
                prepared_entry.Ambito_riferimento = prepared_entry.Ambito_riferimento[1:]
            if prepared_entry.Ambito_riferimento[-1] == " ":
                prepared_entry.Ambito_riferimento = prepared_entry.Ambito_riferimento[0:-1]

        if not pd.isnull(prepared_entry.Autore_definizione):    
            if prepared_entry.Autore_definizione[0] == " ":
                prepared_entry.Autore_definizione = prepared_entry.Autore_definizione[1:]
            if prepared_entry.Autore_definizione[-1] == " ":
                prepared_entry.Autore_definizione = prepared_entry.Autore_definizione[0:-1]

        if not pd.isnull(prepared_entry.Posizione_definizione):    
            if prepared_entry.Posizione_definizione[0] == " ":
                prepared_entry.Posizione_definizione = prepared_entry.Posizione_definizione[1:]
            if prepared_entry.Posizione_definizione[-1] == " ":
                prepared_entry.Posizione_definizione = prepared_entry.Posizione_definizione[0:-1]

        if not pd.isnull(prepared_entry.Url_definizione):    
            if prepared_entry.Url_definizione[0] == " ":
                prepared_entry.Url_definizione = prepared_entry.Url_definizione[1:]
            if prepared_entry.Url_definizione[-1] == " ":
                prepared_entry.Url_definizione = prepared_entry.Url_definizione[0:-1]

        if not pd.isnull(prepared_entry.Titolo_documento_fonte):    
            if prepared_entry.Titolo_documento_fonte[0] == " ":
                prepared_entry.Titolo_documento_fonte = prepared_entry.Titolo_documento_fonte[1:]
            if prepared_entry.Titolo_documento_fonte[-1] == " ":
                prepared_entry.Titolo_documento_fonte = prepared_entry.Titolo_documento_fonte[0:-1]

        if not pd.isnull(prepared_entry.Autore_documento_fonte):    
            if prepared_entry.Autore_documento_fonte[0] == " ":
                prepared_entry.Autore_documento_fonte = prepared_entry.Autore_documento_fonte[1:]
            if prepared_entry.Autore_documento_fonte[-1] == " ":
                prepared_entry.Autore_documento_fonte = prepared_entry.Autore_documento_fonte[0:-1]

        if not pd.isnull(prepared_entry.Host_documento_fonte):    
            if prepared_entry.Host_documento_fonte[0] == " ":
                prepared_entry.Host_documento_fonte = prepared_entry.Host_documento_fonte[1:]
            if prepared_entry.Host_documento_fonte[-1] == " ":
                prepared_entry.Host_documento_fonte = prepared_entry.Host_documento_fonte[0:-1]

        if not pd.isnull(prepared_entry.Url_documento_fonte):    
            if prepared_entry.Url_documento_fonte[0] == " ":
                prepared_entry.Url_documento_fonte = prepared_entry.Url_documento_fonte[1:]
            if prepared_entry.Url_documento_fonte[-1] == " ":
                prepared_entry.Url_documento_fonte = prepared_entry.Url_documento_fonte[0:-1]

        if not pd.isnull(prepared_entry.Commento_entry):    
            if prepared_entry.Commento_entry[0] == " ":
                prepared_entry.Commento_entry = prepared_entry.Commento_entry[1:]
            if prepared_entry.Commento_entry[-1] == " ":
                prepared_entry.Commento_entry = prepared_entry.Commento_entry[0:-1]
        
        if not pd.isnull(prepared_entry.Id_statico_entry):
            if prepared_entry.Id_statico_entry[0] == " ":
                prepared_entry.Id_statico_entry = prepared_entry.Id_statico_entry[1:]
            if prepared_entry.Id_statico_entry[-1] == " ":
                prepared_entry.Id_statico_entry = prepared_entry.Id_statico_entry[0:-1]       


        prepared_entry.save()

        print("Eliminazione degli spazi all'inizio e alla fine di ogni cella terminata con successo!")

        print("Standardizzazione del formato dei dati terminata con successo!")

        print("I dati sono ora in un formato standard e possono essere processati per la realizzazione della struttura relazionale!")


********************


    class GI(object):
        def __init__(self, Lemma, Acronimo, Definizione, Ambito_riferimento, Autore_definizione, Posizione_definizione, Url_definizione, Titolo_documento_fonte, Autore_documento_fonte, Host_documento_fonte, Url_documento_fonte, Commento_entry, Data_inserimento_entry, Id_statico_entry, Admin_approval_switch):
            self.Lemma = Lemma
            self.Acronimo = Acronimo
            self.Definizione = Definizione
            self.Ambito_riferimento = Ambito_riferimento
            self.Autore_definizione = Autore_definizione
            self.Posizione_definizione = Posizione_definizione
            self.Url_definizione = Url_definizione
            self.Titolo_documento_fonte = Titolo_documento_fonte
            self.Autore_documento_fonte = Autore_documento_fonte
            self.Host_documento_fonte = Host_documento_fonte
            self.Url_documento_fonte = Url_documento_fonte
            self.Commento_entry = Commento_entry
            self.Data_inserimento_entry = Data_inserimento_entry
            self.Id_statico_entry = Id_statico_entry
            self.Admin_approval_switch = Admin_approval_switch

        def to_dict(self):
            return {
                'Lemma': self.Lemma,
                'Acronimo': self.Acronimo,
                'Definizione': self.Definizione,
                'Ambito_riferimento': self.Ambito_riferimento,
                'Autore_definizione': self.Autore_definizione,
                'Posizione_definizione': self.Posizione_definizione,
                'Url_definizione': self.Url_definizione,
                'Titolo_documento_fonte': self.Titolo_documento_fonte,
                'Autore_documento_fonte': self.Autore_documento_fonte,
                'Host_documento_fonte': self.Host_documento_fonte,
                'Url_documento_fonte': self.Url_documento_fonte,
                'Commento_entry': self.Commento_entry,
                'Data_inserimento_entry': self.Data_inserimento_entry,
                'Id_statico_entry': self.Id_statico_entry,
                'Admin_approval_switch': self.Admin_approval_switch,
            }
    
        pd.DataFrame.from_records([s.to_dict() for s in signals])


************


#inizializzo un array 2D (matrice) di vuoti
    GI = [["" for x in range(nC)] for y in range(L_GI)] 

    # print(GI)

    i=0
    j=0

    for element in prepared_entries:
        i=i+1      
            
        if not pd.isnull(element.Lemma):
            j=j+1
            GI[i, j] = element.Lemma

        if not pd.isnull(element.Id_statico_entry):
            j=j+1
            GI[i, j] = element.Id_statico_entry

        if not pd.isnull(element.Definizione):    
            j=j+1
            GI[i, j] = element.Definizione

        if not pd.isnull(element.Ambito_riferimento):    
            j=j+1
            GI[i, j] = element.Ambito_riferimento

        if not pd.isnull(element.Autore_definizione):    
            j=j+1
            GI[i, j] = element.Autore_definizione

        if not pd.isnull(element.Posizione_definizione):  
            j=j+1  
            GI[i, j] = element.Posizione_definizione

        if not pd.isnull(element.Url_definizione):   
            j=j+1 
            GI[i, j] = element.Url_definizione

        if not pd.isnull(element.Titolo_documento_fonte):  
            j=j+1  
            GI[i, j] = element.Titolo_documento_fonte

        if not pd.isnull(element.Autore_documento_fonte):    
            j=j+1
            GI[i, j] = element.Autore_documento_fonte

        if not pd.isnull(element.Host_documento_fonte):    
            j=j+1
            GI[i, j] = element.Host_documento_fonte

        if not pd.isnull(element.Url_documento_fonte):    
            j=j+1
            GI[i, j] = element.Url_documento_fonte

        if not pd.isnull(element.Commento_entry):   
            j=j+1 
            GI[i, j] = element.Commento_entry

        j=j+1
        GI[i, j] = element.Data_inserimento_entry

        j=j+1
        GI[i, j] = element.Id_statico_entry      

        j=j+1         
        GI[i, j] = element.Admin_approval_switch
        

        j=0 # fine del ciclo for in j virtuale
        
    i=0

    print(GI)


    *********


    # rimepire il dataframe
    i=0
    j=0

    for element in prepared_entries:
        i=i+1      
            
        print(element.Lemma)

        if not pd.isnull(element.Lemma):
            j=j+1
            GI.iat[i,j] = element.Lemma

        if not pd.isnull(element.Acronimo):
            j=j+1
            GI.iat[i,j] = element.Acronimo

        if not pd.isnull(element.Definizione):    
            j=j+1
            GI.iat[i,j] = element.Definizione

        if not pd.isnull(element.Ambito_riferimento):    
            j=j+1
            GI.iat[i,j] = element.Ambito_riferimento

        if not pd.isnull(element.Autore_definizione):    
            j=j+1
            GI.iat[i,j] = element.Autore_definizione

        if not pd.isnull(element.Posizione_definizione):  
            j=j+1  
            GI.iat[i,j] = element.Posizione_definizione

        if not pd.isnull(element.Url_definizione):   
            j=j+1 
            GI.iat[i,j] = element.Url_definizione

        if not pd.isnull(element.Titolo_documento_fonte):  
            j=j+1  
            GI.iat[i,j] = element.Titolo_documento_fonte

        if not pd.isnull(element.Autore_documento_fonte):    
            j=j+1
            GI.iat[i,j] = element.Autore_documento_fonte

        if not pd.isnull(element.Host_documento_fonte):    
            j=j+1
            GI.iat[i,j] = element.Host_documento_fonte

        if not pd.isnull(element.Url_documento_fonte):    
            j=j+1
            GI.iat[i,j] = element.Url_documento_fonte

        if not pd.isnull(element.Commento_entry):   
            j=j+1 
            GI.iat[i,j] = element.Commento_entry

        j=j+1
        GI.iat[i,j] = element.Data_inserimento_entry

        j=j+1
        GI.iat[i,j] = element.Id_statico_entry      

        j=j+1         
        GI.iat[i,j] = element.Admin_approval_switch
        
        print(i)

        if i == 999:
            print(GI)


        j=0 # fine del ciclo for in j virtuale
        
    i=0

    print(GI)




    ********


    print("Viene preparata la tabella di ID e terminologia Elab1")
    

    Elab1 = Elab1.sort_values(['Lemma', 'Id_statico_entry'])
    Elab1.ID_db_Lemma = IDs_prestampa.ID_db_Lemma
   

    Elab1 = Elab1.sort_values(['Acronimo', 'Id_statico_entry'])
    Elab1.ID_db_Acronimo = IDs_prestampa.ID_db_Acronimo
    

    Elab1 = Elab1.sort_values(['Definizione', 'Id_statico_entry'])
    Elab1.ID_db_Definizione = IDs_prestampa.ID_db_Definizione
    print(Elab1)

    Elab1 = Elab1.sort_values(['Ambito_riferimento', 'Id_statico_entry'])
    Elab1.ID_db_Ambito_riferimento = IDs_prestampa.ID_db_Ambito_riferimento

    Elab1 = Elab1.sort_values(['Autore_definizione', 'Id_statico_entry'])
    Elab1.ID_db_Autore_definizione = IDs_prestampa.ID_db_Autore_definizione

    Elab1 = Elab1.sort_values(['Posizione_definizione', 'Id_statico_entry'])
    Elab1.ID_db_Posizione_definizione = IDs_prestampa.ID_db_Posizione_definizione

    Elab1 = Elab1.sort_values(['Url_definizione', 'Id_statico_entry'])
    Elab1.ID_db_Url_definizione = IDs_prestampa.ID_db_Url_definizione

    Elab1 = Elab1.sort_values(['Titolo_documento_fonte', 'Id_statico_entry'])
    Elab1.ID_db_Titolo_documento_fonte = IDs_prestampa.ID_db_Titolo_documento_fonte

    Elab1 = Elab1.sort_values(['Autore_documento_fonte', 'Id_statico_entry'])
    Elab1.ID_db_Autore_documento_fonte = IDs_prestampa.ID_db_Autore_documento_fonte

    Elab1 = Elab1.sort_values(['Host_documento_fonte', 'Id_statico_entry'])
    Elab1.ID_db_Host_documento_fonte = IDs_prestampa.ID_db_Host_documento_fonte

    Elab1 = Elab1.sort_values(['Url_documento_fonte', 'Id_statico_entry'])
    Elab1.ID_db_Url_documento_fonte = IDs_prestampa.ID_db_Url_documento_fonte

    Elab1 = Elab1.sort_values(['Commento_entry', 'Id_statico_entry'])
    Elab1.ID_db_Commento_entry = IDs_prestampa.ID_db_Commento_entry

    Elab1 = Elab1.sort_values(['Data_inserimento_entry', 'Id_statico_entry'])
    Elab1.ID_db_Data_inserimento_entry = IDs_prestampa.ID_db_Data_inserimento_entry

    Elab1 = Elab1.sort_values(['Id_statico_entry'])
    Elab1.ID_db_Id_statico_entry = IDs_prestampa.ID_db_Id_statico_entry

    Elab1 = Elab1.sort_values(['Admin_approval_switch', 'Id_statico_entry'])
    Elab1.ID_db_Admin_approval_switch = IDs_prestampa.ID_db_Admin_approval_switch


    Elab1 = Elab1.sort_values(['Lemma', 'Id_statico_entry'])


    print("Gli ID di Elab 1 vengono assegnati in ordine ascendente con l'ordine alfabetico di ogni colonna")

    print(Elab1)


    
********


   # nuovo campo da processare

    print("fine prova")

    print("Ricerca dei lemmi uguali...")

    Elab1 = Elab1.sort_values(['Lemma', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Lemma"] == Elab1.at[i, "Lemma"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Lemma"] = Elab1.at[i, "ID_db_Lemma"]

    
    

    #nuovo campo da processare

    print("Ricerca degli acronimi uguali...")
    
    Elab1 = Elab1.sort_values(['Acronimo', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Acronimo"] == Elab1.at[i, "Acronimo"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Acronimo"] = Elab1.at[i, "ID_db_Acronimo"]

    #nuovo campo da processare
    
    print("Ricerca delle definizioni uguali...")

    Elab1 = Elab1.sort_values(['Definizione', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Definizione"] == Elab1.at[i, "Definizione"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Definizione"] = Elab1.at[i, "ID_db_Definizione"]


    #nuovo campo da processare

    print("Ricerca degli ambiti di riferimento uguali...")
    
    Elab1 = Elab1.sort_values(['Ambito_riferimento', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Ambito_riferimento"] == Elab1.at[i, "Ambito_riferimento"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Ambito_riferimento"] = Elab1.at[i, "ID_db_Ambito_riferimento"]


    #nuovo campo da processare

    print("Ricerca degli ambiti di Autore_definizione uguali...")
        
    Elab1 = Elab1.sort_values(['Autore_definizione', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Autore_definizione"] == Elab1.at[i, "Autore_definizione"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Autore_definizione"] = Elab1.at[i, "ID_db_Autore_definizione"]


    #nuovo campo da processare

    print("Ricerca delle posizioni delle definizioni uguali...")
        
    Elab1 = Elab1.sort_values(['Posizione_definizione', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Posizione_definizione"] == Elab1.at[i, "Posizione_definizione"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Posizione_definizione"] = Elab1.at[i, "ID_db_Posizione_definizione"]


    #nuovo campo da processare

    print("Ricerca delgli url delle definizioni uguali...")
        
    Elab1 = Elab1.sort_values(['Url_definizione', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Url_definizione"] == Elab1.at[i, "Url_definizione"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Url_definizione"] = Elab1.at[i, "ID_db_Url_definizione"]


    #nuovo campo da processare

    print("Ricerca dei Titolo_documento_fonte uguali...")
        
    Elab1 = Elab1.sort_values(['Titolo_documento_fonte', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Titolo_documento_fonte"] == Elab1.at[i, "Titolo_documento_fonte"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Titolo_documento_fonte"] = Elab1.at[i, "ID_db_Titolo_documento_fonte"]


#nuovo campo da processare

    print("Ricerca dei Autore_documento_fonte uguali...")
    
    Elab1 = Elab1.sort_values(['Autore_documento_fonte', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Autore_documento_fonte"] == Elab1.at[i, "Autore_documento_fonte"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Autore_documento_fonte"] = Elab1.at[i, "ID_db_Autore_documento_fonte"]


#nuovo campo da processare

    print("Ricerca dei Host_documento_fonte uguali...")
    
    Elab1 = Elab1.sort_values(['Host_documento_fonte', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Host_documento_fonte"] == Elab1.at[i, "Host_documento_fonte"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Host_documento_fonte"] = Elab1.at[i, "ID_db_Host_documento_fonte"]


#nuovo campo da processare

    print("Ricerca dei Url_documento_fonte uguali...")
    
    Elab1 = Elab1.sort_values(['Url_documento_fonte', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Url_documento_fonte"] == Elab1.at[i, "Url_documento_fonte"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Url_documento_fonte"] = Elab1.at[i, "ID_db_Url_documento_fonte"]


#nuovo campo da processare

    print("Ricerca dei Commento_entry uguali...")
    
    Elab1 = Elab1.sort_values(['Commento_entry', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Commento_entry"] == Elab1.at[i, "Commento_entry"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Commento_entry"] = Elab1.at[i, "ID_db_Commento_entry"]


#nuovo campo da processare

    print("Ricerca delle date_entry uguali...")
    
    Elab1 = Elab1.sort_values(['Data_inserimento_entry', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Data_inserimento_entry"] == Elab1.at[i, "Data_inserimento_entry"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Data_inserimento_entry"] = Elab1.at[i, "ID_db_Data_inserimento_entry"]


#nuovo campo da processare
    
    # Id_statico_entry slta perchè sicuramente è univoco

    # nel foglio excel di ingresso devo fare un meccanismo per assegnare gli id ma li fa l'utore


#nuovo campo da processare

    print("Ricerca degli Admin_approval_switch uguali...")
    
    Elab1 = Elab1.sort_values(['Admin_approval_switch', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    # uno in meno perchè devo fare confronto tra i e i+1
    for i in range(L_GI-1):

        # se gli oggetti consecutivi sono uguali
        if Elab1.at[i+1, "Admin_approval_switch"] == Elab1.at[i, "Admin_approval_switch"] :

            # poni l'id successivo uguale a quello attuale
            Elab1.at[i+1, "ID_db_Admin_approval_switch"] = Elab1.at[i, "ID_db_Admin_approval_switch"]


            *********




    Elab1 = Elab1.sort_values(['Lemma', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Lemma = IDs_prestampa.ID_db_Lemma   

    Elab1 = Elab1.sort_values(['Acronimo', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Acronimo = IDs_prestampa.ID_db_Acronimo    

    Elab1 = Elab1.sort_values(['Definizione', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Definizione = IDs_prestampa.ID_db_Definizione

    Elab1 = Elab1.sort_values(['Ambito_riferimento', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Ambito_riferimento = IDs_prestampa.ID_db_Ambito_riferimento

    Elab1 = Elab1.sort_values(['Autore_definizione', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Autore_definizione = IDs_prestampa.ID_db_Autore_definizione

    Elab1 = Elab1.sort_values(['Posizione_definizione', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Posizione_definizione = IDs_prestampa.ID_db_Posizione_definizione

    Elab1 = Elab1.sort_values(['Url_definizione', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Url_definizione = IDs_prestampa.ID_db_Url_definizione

    Elab1 = Elab1.sort_values(['Titolo_documento_fonte', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Titolo_documento_fonte = IDs_prestampa.ID_db_Titolo_documento_fonte

    Elab1 = Elab1.sort_values(['Autore_documento_fonte', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Autore_documento_fonte = IDs_prestampa.ID_db_Autore_documento_fonte

    Elab1 = Elab1.sort_values(['Host_documento_fonte', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Host_documento_fonte = IDs_prestampa.ID_db_Host_documento_fonte

    Elab1 = Elab1.sort_values(['Url_documento_fonte', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Url_documento_fonte = IDs_prestampa.ID_db_Url_documento_fonte

    Elab1 = Elab1.sort_values(['Commento_entry', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Commento_entry = IDs_prestampa.ID_db_Commento_entry

    Elab1 = Elab1.sort_values(['Data_inserimento_entry', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Data_inserimento_entry = IDs_prestampa.ID_db_Data_inserimento_entry

    Elab1 = Elab1.sort_values(['Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Id_statico_entry = IDs_prestampa.ID_db_Id_statico_entry

    Elab1 = Elab1.sort_values(['Admin_approval_switch', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)
    Elab1.ID_db_Admin_approval_switch = IDs_prestampa.ID_db_Admin_approval_switch


    *********


        for j in range(nC):

        Elab1 = Elab1.sort_values([nomi_campi_prepared_terminology[j], 'Id_statico_entry'])
        Elab1 = Elab1.reset_index(drop=True)
        Elab1.nomi_campi_prepared_terminology[j+nC] = IDs_prestampa.nomi_campi_prepared_terminology[j+nC]   


    Elab1 = Elab1.sort_values(['Lemma', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)


    *******


    oggetti_univoci_content.append([ L_GI - ripetizioni.iloc[0, j] for j in range(nC) ])  


     raise IndexError("single positional indexer is out-of-bounds")
IndexError: single positional indexer is out-of-bounds

perchè le etichette per il ciclaggio non erano uguali



'Series' object has no attribute 'columns'
nella serie manca la colonna che stai cercando
stavo copiando admina pproval nell asse sbagliato (0 anxiche 1)


***********************

def algoritmo_SR():

    # algoritmo per standardizzare i dati prima di incatenarli nella struttura relazionale

    # nota: ci sono dati con lo stesso ID perchè sono i lemmi inglesi eliminati

    import numpy as np
    import pandas as pd
    from app_metaglossario.models import prepared_terminology
    from app_metaglossario.models import displaying_terminology
    # from app_metaglossario.metaglossary_models import 

    # devo modificare

    ###############################
    ###  CONTROLLI e PARAMETRI
    ###############################


    #setta la dimensione dell'ID
    
    ID_dimension = 1000000

    print("Inizia la creazione della struttura relazionale dei dati contenuti in prepared_terminology...")
    
    # copia i dati del modello prepared_terminology in un dataframe    

    prepared_entries = prepared_terminology.objects.all()   

    # genera un oggettos trano che contine i nomi delle colonne
    # nomi_campi_prepared_terminology = prepared_terminology._meta.fields

    # devo trovare il modo per farlo in automatico
    # nomi_campi_prepared_terminology = ["Lemma", "Acronimo", "Definizione", "Ambito_riferimento", "Autore_definizione", "Posizione_definizione", "Url_definizione", "Titolo_documento_fonte", "Autore_documento_fonte", "Host_documento_fonte", "Url_documento_fonte", "Commento_entry", "Data_inserimento_entry", "Id_statico_entry", "Admin_approval_switch"]

    # lista coi nomi delle colonne del modello
    nomi_campi_prepared_terminology = [field.name for field in prepared_terminology._meta.get_fields()[1:]]

    # elimino la colonna dell'id stabilito da python
    # nomi_campi_prepared_terminology = nomi_campi_prepared_terminology[1:]

    L_GI = len(prepared_entries)
    nC = len(nomi_campi_prepared_terminology)

    print("Vengono impostate le dimensioni del dataframe:")
    print("Righe (L_GI): %s" % L_GI)
    print("Colonne (nC): %s" % nC)   


    print("Viene generato il dataframe che contiene la copia dei dati del modello prepared_terminology...")

    # creo il dataframe
    GI = pd.DataFrame(columns=nomi_campi_prepared_terminology)

    # print(GI)


    for element in prepared_entries:

        # "Lemma", "Acronimo", "Definizione", "Ambito_riferimento", "Autore_definizione", "Posizione_definizione", "Url_definizione", "Titolo_documento_fonte", "Autore_documento_fonte", "Host_documento_fonte", "Url_documento_fonte", "Commento_entry", "Data_inserimento_entry", "Id_statico_entry", "Admin_approval_switch"
        new_entry = {"Lemma":element.Lemma, "Acronimo":element.Acronimo, "Definizione":element.Definizione, "Ambito_riferimento":element.Ambito_riferimento, "Autore_definizione":element.Autore_definizione, "Posizione_definizione":element.Posizione_definizione, "Url_definizione":element.Url_definizione, "Titolo_documento_fonte":element.Titolo_documento_fonte, "Autore_documento_fonte":element.Autore_documento_fonte, "Host_documento_fonte":element.Host_documento_fonte, "Url_documento_fonte":element.Url_documento_fonte, "Commento_entry":element.Commento_entry, "Data_inserimento_entry":element.Data_inserimento_entry, "Id_statico_entry":element.Id_statico_entry, "Admin_approval_switch":element.Admin_approval_switch}
        
        GI = GI.append(new_entry, ignore_index=True)

  
    GI = GI.sort_values(['Lemma', 'Id_statico_entry'])
    GI = GI.reset_index(drop=True)

    print(GI)



    # preparo il tabellone fatto con le tabelle di ID e campi corrispondenti adiacenti    
    print("Vengono preparati gli ID da associare a ciascun oggetto del metaglossario...")

    label_IDs_prestampa = []

    for i in range(nC):
        label_IDs_prestampa.append("ID_db_" + nomi_campi_prepared_terminology[i])
    
    ID_dimension = 1000000

    IDs_prestampa_content = []

    # mentre per python il primo indice è 0, nella mia riga io ci metto 1
    for i in range(L_GI):        
        IDs_prestampa_content.append([ (ID_dimension * (j+1) ) + (i+1) for j in range(nC) ])
            

    IDs_prestampa = pd.DataFrame(IDs_prestampa_content, columns=label_IDs_prestampa)   



    # devo ordinare dalla A alla Z la tabella della terminolgia
    # poi devo reincollare il vettore di ogni colonna già ordinata dalla A alla Z


    Elab1 = pd.concat([IDs_prestampa, GI], axis=1)

    print("Viene preparata la tabella di ID e terminologia Elab1...")

    print("Gli ID di Elab 1 vengono assegnati in ordine numerico ascendente con l'ordine alfabetico (A->Z) di ogni colonna.")

    


    # vedi i print
    for j in range(nC):

        Elab1 = Elab1.sort_values([nomi_campi_prepared_terminology[j], "Id_statico_entry"])
        Elab1 = Elab1.reset_index(drop=True)
        Elab1.iloc[:, j] = IDs_prestampa.iloc[:, j]   
        


    Elab1 = Elab1.sort_values(['Lemma', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    
    print(Elab1)

    # tengo traccia delle ripetizioni presenti in ogni colonna del dataframe

    # creo le labe per il df ripetizioni
    label_ripetizioni = []

    for i in range(nC):
        label_ripetizioni.append("Ripetizioni_di_" + nomi_campi_prepared_terminology[i])

    # creo i dati per il df ripetizioni
    ripetizioni_content = []
    
    ripetizioni_content.append([ 0 for j in range(nC) ])

    # creo  il df ripetizioni
    ripetizioni = pd.DataFrame(ripetizioni_content, columns=label_ripetizioni)
    

    # inizia la riscrittura degli id per mettere uguali queli che corrispondono ad oggetti uguali

    #ordino il glossario alfabeticamente per X

    # pone uguali id di elementi guuali


    # salto il fatto che id statico non ha ripetizioni perchè c'è l'interruttore di show/hide

    label_Elab1 = nomi_campi_prepared_terminology + label_IDs_prestampa

    print("Inizia lo scansionamento della terminologia e dei metadati per individuare elementi uguali...")
    
    
    # faccio il megaciclo in cui rendo uguagli gli id di oggetti uguali adiacenti (ordiant in ordine alfabetico)
    for j in range(nC):

        Elab1 = Elab1.sort_values([nomi_campi_prepared_terminology[j], "Id_statico_entry"])
        Elab1 = Elab1.reset_index(drop=True)

        # uno in meno perchè devo fare confronto tra i e i+1
        for i in range(L_GI-1):

            # se gli oggetti consecutivi sono uguali
            if Elab1.iloc[i+1, j+nC] == Elab1.iloc[i, j+nC] :

                # poni l'id successivo uguale a quello attuale
                Elab1.iloc[i+1, j] = Elab1.iloc[i, j] 

                ripetizioni.iloc[0, j] = ripetizioni.iloc[0, j] + 1


    Elab1 = Elab1.sort_values(["Lemma", "Id_statico_entry"])
    Elab1 = Elab1.reset_index(drop=True)
 

    print(Elab1)

    # creo un dataframe per gli ogetti univoci (L_GI-ripetizioni)

    label_oggetti_univoci = []

    for j in range(nC):
        label_oggetti_univoci.append("Oggetti_univoci_di_" + nomi_campi_prepared_terminology[j])

    # creo i dati per il df ripetizioni
    oggetti_univoci_content = []
    
    oggetti_univoci_content.append([ L_GI - ripetizioni.iloc[0, j] for j in range(nC) ])   
    

    # creo  il df ripetizioni
    oggetti_univoci = pd.DataFrame(oggetti_univoci_content, columns=label_oggetti_univoci)

    

    print("Il metaglossario Elab1 possiede i seguenti numeri di oggetti univoci:")

    print(np.transpose(oggetti_univoci))


    # Inizia il ciclo di sostituzioni degli ID con ID ordinati in linea con gli ID statici

    #  ossia:
    #  tutte le colonne sono ordinate per ID statici,
    #  un ciclo i scorre le colonne, e:
    #  un ciclo j scorre tutta la colonna, e:
    #  l'ID corrente(j) viene salvato come bersaglio da sostituire
    #  viene generato un ID del tipo x000000[contatore del ciclo j /ossia prestampaIDs(j,i)] e salvato come sostituto
    #  un ciclo k scorre tutta la colonna DALLA CELLA CORRENTE VERSO IL BASSO (onde evitare di sovrascrivere i precedenti) e sostituisce altre celle uguali al bersaglio con il sostuituto

    print("Viene eseguita la riclassificazione degli ID dei singoli oggetti per realizzare le tabelle relazionali del database...")

    # col_scan 1 To L_GI, 1 To nC
    # avvenuta_sost  1 To L_GI, 1 To nC

    #  va bene anche df_zeros = df * 0

    avvenuta_sost = pd.DataFrame(0, index=np.arange(len(GI)), columns=label_IDs_prestampa)


    # ordino il glossario alfabeticamente per IDS, una sola volta
    Elab1 = Elab1.sort_values("Id_statico_entry")
    Elab1 = Elab1.reset_index(drop=True)

    # in col scan ci metto gli id di elab1 ordinati per ids
    col_scan = Elab1[label_IDs_prestampa]

    

    pd.options.mode.chained_assignment = None  # default='warn'
    # https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas

    # in VBA, solo negli offset accade che righe e colonne hanno il sistema ribaltato rispetto a x=0 e coordinate scambiate
    # nelle matrici si ragiona normalmente in (righe, colonne)

    for i in range(nC):
    # ciclo delle colonne
    # per l'ID statico non devo farlo ... ma non è più in ultima poizione

        for j in range(L_GI):
        #ciclo delle righe

            Bersaglio = col_scan.iloc[j, i]
            Sostituto = IDs_prestampa.iloc[j, i] # questi sono gli id 1000001 , 10000002, ecc

            

            for k in range(j, L_GI): #[j, j+1,...,L_GI-1, L_GI]
            # ciclo del check per una riga di tutti i duoi doppioni nella colonna
            # 'deve andare fino a L_GI-1 : deve controllare la colonna fino in fondo, ma senza modificare gli elementi prima della colonna j
            # 'ciclo di sola sostituzione: non mettere else

                

                if col_scan.iloc[k, i] == Bersaglio and avvenuta_sost.iloc[k, i] == 0:
                            
                    col_scan.iloc[k, i] = Sostituto                             
                    avvenuta_sost.iloc[k, i] = 1


    # incollo col_scan sulla parte ID di Elab 1
    
    Elab1[ label_IDs_prestampa ] = col_scan [label_IDs_prestampa]

    print(Elab1[ label_IDs_prestampa ])

    del IDs_prestampa

    # 'ora devo compattare gli ID per non lasciare buchi
    for j in range(nC):

        Elab1 = Elab1.sort_values([nomi_campi_prepared_terminology[j], "Id_statico_entry"])
        Elab1 = Elab1.reset_index(drop=True)
        

    Elab1 = Elab1.sort_values(["Id_statico_entry"])
    Elab1 = Elab1.reset_index(drop=True)

    print(Elab1)

    print("Vengono generate le tabelle per il database...")

    print("Viene generata la tabella delle entità Things con tutti gli oggetti del database e i loro Id relazionali...")

    # creazione della tabella things: id e oggetti
    # concat: axis: 0 per la concatenazione in colonna, 1 per la concatenazione in riga

    # concatena in colonna gli id di tutti gli oggetti
    # incolla uno sotto l'altra le colonne degli id
    Things_ID = pd.concat([Elab1[j] for j in nomi_campi_prepared_terminology], axis=0) 

    print(Things_ID)

    # concatena in colonna gli oggetti
     # incolla uno sotto l'altra le colonne degli oggetti
    Things_oggetti = pd.concat([Elab1[j] for j in label_IDs_prestampa], axis=0)

    print(Things_oggetti)
    

    # crea la tabella things
    # concatena in riga id e oggetti    
    Things_content = pd.concat([Things_ID, Things_oggetti], axis=1) # non è dataframe
    print(Things_content)

    # qui me lo sovrascrive ma non capisco perchè
    Things = pd.DataFrame(Things_content, columns=['ID_db_Thing','Thing']) # è dataframe

    # resetto gli indici altrimenti mi tiene gli indici di Elab1
    Things = Things.reset_index(drop=True)

    print(Things)

    print("Vengono generate le tabelle relazionali...")


    # ["Lemma", "Acronimo", "Definizione", "Ambito_riferimento", "Autore_definizione", "Posizione_definizione", "
    # Url_definizione", "Titolo_documento_fonte", "Autore_documento_fonte", "Host_documento_fonte", 
    # "Url_documento_fonte", "Commento_entry", "Data_inserimento_entry", "Id_statico_entry", "Admin_approval_switch"]
    
    # ID_db_

    is_Acronimo_of = pd.concat([ Elab1["ID_db_Acronimo"], Elab1["ID_db_Lemma"], Elab1["Acronimo"], Elab1["Lemma"] ], axis=1)

    is_Lemma_of = pd.concat( [Elab1["ID_db_Lemma"], Elab1["ID_db_Definizione"], Elab1["Lemma"], Elab1["Definizione"] ], axis=1)

    is_Ambito_riferimento_of = pd.concat([ Elab1["ID_db_Ambito_riferimento"], Elab1["ID_db_Definizione"], Elab1["Ambito_riferimento"], Elab1["Definizione"] ], axis=1)

    is_Autore_definizione_of = pd.concat([ Elab1["ID_db_Autore_definizione"], Elab1["ID_db_Definizione"], Elab1["Autore_definizione"], Elab1["Definizione"] ], axis=1)

    is_Posizione_definizione_of = pd.concat([ Elab1["ID_db_Posizione_definizione"], Elab1["ID_db_Definizione"], Elab1["Posizione_definizione"], Elab1["Definizione"] ], axis=1)

    is_Url_definizione_of = pd.concat([ Elab1["ID_db_Url_definizione"], Elab1["ID_db_Definizione"], Elab1["Url_definizione"], Elab1["Definizione"] ], axis=1)

    # is_Titolo_documento_fonte_of = pd.concat([ Elab1["ID_db_Ambito_riferimento"], Elab1["ID_db_Definizione"], Elab1["Ambito_riferimento"], Elab1["Definizione"] ], axis=1)

    is_Autore_documento_fonte_of = pd.concat([ Elab1["ID_db_Autore_documento_fonte"], Elab1["ID_db_Titolo_documento_fonte"], Elab1["Autore_documento_fonte"], Elab1["Titolo_documento_fonte"] ], axis=1)

    is_Host_documento_fonte_of = pd.concat([ Elab1["ID_db_Host_documento_fonte"], Elab1["ID_db_Titolo_documento_fonte"], Elab1["Host_documento_fonte"], Elab1["Titolo_documento_fonte"] ], axis=1)

    is_Url_documento_fonte_of = pd.concat([ Elab1["ID_db_Url_documento_fonte"], Elab1["ID_db_Titolo_documento_fonte"], Elab1["Url_documento_fonte"], Elab1["Titolo_documento_fonte"] ], axis=1)

    is_Commento_entry_of = pd.concat([ Elab1["ID_db_Commento_entry"], Elab1["ID_db_Id_statico_entry"], Elab1["Commento_entry"], Elab1["Id_statico_entry"] ], axis=1)
    
    is_Data_inserimento_entry_of = pd.concat([ Elab1["ID_db_Data_inserimento_entry"], Elab1["ID_db_Id_statico_entry"], Elab1["Data_inserimento_entry"], Elab1["Id_statico_entry"] ], axis=1)
    

    # is_Id_statico_entry_of è lunga nC*L_GI perchè collega gli id_statici a nC entità del database

    Id_statico_entry_impilati_per_nC = pd.concat([Elab1["Id_statico_entry"] for j in range(nC)], axis=0)   
    # resetto gli indici altrimenti mi tiene gli indici di Elab1
    Id_statico_entry_impilati_per_nC = Id_statico_entry_impilati_per_nC.reset_index(drop=True)
    Id_statico_entry_impilati_per_nC = pd.DataFrame(Id_statico_entry_impilati_per_nC) # è dataframe

    ID_db_Id_statico_entry_impilati_per_nC = pd.concat([Elab1["ID_db_Id_statico_entry"] for j in range(nC)], axis=0)  
    # resetto gli indici altrimenti mi tiene gli indici di Elab1
    ID_db_Id_statico_entry_impilati_per_nC = ID_db_Id_statico_entry_impilati_per_nC.reset_index(drop=True)
    ID_db_Id_statico_entry_impilati_per_nC = pd.DataFrame(ID_db_Id_statico_entry_impilati_per_nC) # è dataframe
  

   
    is_Id_statico_entry_of = pd.concat( [ ID_db_Id_statico_entry_impilati_per_nC, Id_statico_entry_impilati_per_nC, Things ], axis=1)




    is_Admin_approval_switch_of = pd.concat([ Elab1["ID_db_Admin_approval_switch"], Elab1["ID_db_Id_statico_entry"], Elab1["Admin_approval_switch"], Elab1["Id_statico_entry"] ], axis=1)
    
    del Elab1


    ###########

    # ELIMINA LE RIGHE RIPETUTE dalle tabelle relazionali

    print("La tabella delle entità e le tabelle relazionali vengono ripulite degli elementi ridondanti")

    Tabelle_relazionali = [is_Acronimo_of, is_Lemma_of, is_Ambito_riferimento_of, is_Autore_definizione_of, is_Posizione_definizione_of, is_Url_definizione_of, is_Autore_documento_fonte_of, is_Host_documento_fonte_of, is_Url_documento_fonte_of, is_Commento_entry_of, is_Data_inserimento_entry_of, is_Id_statico_entry_of, is_Admin_approval_switch_of]


    label_righe_eliminate = []

    for i in range(nC):
        label_righe_eliminate.append("Righe_eliminate_di_" + nomi_campi_prepared_terminology[i])

    # creo i dati per il df righe_eliminate
    righe_eliminate_content = []
    
    righe_eliminate_content.append([ 0 for j in range(nC) ])

    # creo il df righe_eliminate
    righe_eliminate = pd.DataFrame(righe_eliminate_content, columns=label_righe_eliminate)

    j=0

    for tabella in Tabelle_relazionali:

        colonne_tabella = list(tabella.columns.values)        

        tabella = tabella.sort_values( [ colonne_tabella[0], colonne_tabella[1] ] )
        tabella = tabella.reset_index(drop=True)
    
        last_ID_unique_A = tabella.iloc[0, 0] 
        last_ID_unique_B = tabella.iloc[0, 1] 


        for i in range(1,L_GI): # da 1 a L_GI

            if tabella.iloc[i, 0] == last_ID_unique_A and tabella.iloc[i, 1] == last_ID_unique_B:

                tabella.iloc[i, :] = "ELIMINARE"
                righe_eliminate.iloc[0, j] = righe_eliminate.iloc[0, j] + 1

            else:
                last_ID_unique_A = tabella.iloc[i, 0] 
                last_ID_unique_B = tabella.iloc[i, 1] 

        

        
        indexNames = tabella[ tabella[colonne_tabella[0]] == "ELIMINARE" ].index
 
        # Delete these row indexes from dataFrame
        tabella.drop(indexNames , inplace=True)
        tabella = tabella.reset_index(drop=True)

        print(tabella)

        j=j+1

    print(np.transpose(righe_eliminate))


    # ####################

    displaying_terminology.objects.all().delete()
    print("Eliminati tutti i dati dentro displaying_terminology!")


    # il 3-ciclo è momentaneamente dsattivato


****************************

def algoritmo_SR():

    # algoritmo per standardizzare i dati prima di incatenarli nella struttura relazionale

    # nota: ci sono dati con lo stesso ID perchè sono i lemmi inglesi eliminati

    import numpy as np
    import pandas as pd
    from app_metaglossario.models import prepared_terminology
    from app_metaglossario.models import displaying_terminology
    # from app_metaglossario.metaglossary_models import 

    # devo modificare

    ###############################
    ###  CONTROLLI e PARAMETRI
    ###############################


    #setta la dimensione dell'ID
    
    ID_dimension = 1000000

    print("Inizia la creazione della struttura relazionale dei dati contenuti in prepared_terminology...")
    
    # copia i dati del modello prepared_terminology in un dataframe    

    prepared_entries = prepared_terminology.objects.all()   

    # genera un oggettos trano che contine i nomi delle colonne
    # nomi_campi_prepared_terminology = prepared_terminology._meta.fields

    # devo trovare il modo per farlo in automatico
    # nomi_campi_prepared_terminology = ["Lemma", "Acronimo", "Definizione", "Ambito_riferimento", "Autore_definizione", "Posizione_definizione", "Url_definizione", "Titolo_documento_fonte", "Autore_documento_fonte", "Host_documento_fonte", "Url_documento_fonte", "Commento_entry", "Data_inserimento_entry", "Id_statico_entry", "Admin_approval_switch"]

    # lista coi nomi delle colonne del modello
    nomi_campi_prepared_terminology = [field.name for field in prepared_terminology._meta.get_fields()[1:]]

    # elimino la colonna dell'id stabilito da python
    # nomi_campi_prepared_terminology = nomi_campi_prepared_terminology[1:]

    L_GI = len(prepared_entries)
    nC = len(nomi_campi_prepared_terminology)

    print("Vengono impostate le dimensioni del dataframe:")
    print("Righe (L_GI): %s" % L_GI)
    print("Colonne (nC): %s" % nC)   


    print("Viene generato il dataframe che contiene la copia dei dati del modello prepared_terminology...")

    # creo il dataframe
    GI = pd.DataFrame(columns=nomi_campi_prepared_terminology)

    # print(GI)


    for element in prepared_entries:

        # "Lemma", "Acronimo", "Definizione", "Ambito_riferimento", "Autore_definizione", "Posizione_definizione", "Url_definizione", "Titolo_documento_fonte", "Autore_documento_fonte", "Host_documento_fonte", "Url_documento_fonte", "Commento_entry", "Data_inserimento_entry", "Id_statico_entry", "Admin_approval_switch"
        new_entry = {"Lemma":element.Lemma, "Acronimo":element.Acronimo, "Definizione":element.Definizione, "Ambito_riferimento":element.Ambito_riferimento, "Autore_definizione":element.Autore_definizione, "Posizione_definizione":element.Posizione_definizione, "Url_definizione":element.Url_definizione, "Titolo_documento_fonte":element.Titolo_documento_fonte, "Autore_documento_fonte":element.Autore_documento_fonte, "Host_documento_fonte":element.Host_documento_fonte, "Url_documento_fonte":element.Url_documento_fonte, "Commento_entry":element.Commento_entry, "Data_inserimento_entry":element.Data_inserimento_entry, "Id_statico_entry":element.Id_statico_entry, "Admin_approval_switch":element.Admin_approval_switch}
        
        GI = GI.append(new_entry, ignore_index=True)

  
    GI = GI.sort_values(['Lemma', 'Id_statico_entry'])
    GI = GI.reset_index(drop=True)

    print(GI)



    # preparo il tabellone fatto con le tabelle di ID e campi corrispondenti adiacenti    
    print("Vengono preparati gli ID da associare a ciascun oggetto del metaglossario...")

    label_IDs_prestampa = []

    for i in range(nC):
        label_IDs_prestampa.append("ID_db_" + nomi_campi_prepared_terminology[i])
    
    ID_dimension = 1000000

    IDs_prestampa_content = []

    # mentre per python il primo indice è 0, nella mia riga io ci metto 1
    for i in range(L_GI):        
        IDs_prestampa_content.append([ (ID_dimension * (j+1) ) + (i+1) for j in range(nC) ])
            

    IDs_prestampa = pd.DataFrame(IDs_prestampa_content, columns=label_IDs_prestampa)   

    del IDs_prestampa_content

    # devo ordinare dalla A alla Z la tabella della terminolgia
    # poi devo reincollare il vettore di ogni colonna già ordinata dalla A alla Z


    Elab1 = pd.concat([IDs_prestampa, GI], axis=1)

    print("Viene preparata la tabella di ID e terminologia Elab1...")

    print("Gli ID di Elab 1 vengono assegnati in ordine numerico ascendente con l'ordine alfabetico (A->Z) di ogni colonna.")

    del GI


    # vedi i print
    for j in range(nC):

        Elab1 = Elab1.sort_values([nomi_campi_prepared_terminology[j], "Id_statico_entry"])
        Elab1 = Elab1.reset_index(drop=True)
        Elab1.iloc[:, j] = IDs_prestampa.iloc[:, j]   
        


    Elab1 = Elab1.sort_values(['Lemma', 'Id_statico_entry'])
    Elab1 = Elab1.reset_index(drop=True)

    
    print(Elab1)

    # tengo traccia delle ripetizioni presenti in ogni colonna del dataframe

    # creo le labe per il df ripetizioni
    label_ripetizioni = []

    for i in range(nC):
        label_ripetizioni.append("Ripetizioni_di_" + nomi_campi_prepared_terminology[i])

    # creo i dati per il df ripetizioni
    ripetizioni_content = []
    
    ripetizioni_content.append([ 0 for j in range(nC) ])

    # creo  il df ripetizioni
    ripetizioni = pd.DataFrame(ripetizioni_content, columns=label_ripetizioni)
    

    # inizia la riscrittura degli id per mettere uguali queli che corrispondono ad oggetti uguali

    #ordino il glossario alfabeticamente per X

    # pone uguali id di elementi guuali


    # salto il fatto che id statico non ha ripetizioni perchè c'è l'interruttore di show/hide

    label_Elab1 = nomi_campi_prepared_terminology + label_IDs_prestampa

    print("Inizia lo scansionamento della terminologia e dei metadati per individuare elementi uguali...")
    
    
    # faccio il megaciclo in cui rendo uguagli gli id di oggetti uguali adiacenti (ordiant in ordine alfabetico)
    for j in range(nC):

        Elab1 = Elab1.sort_values([nomi_campi_prepared_terminology[j], "Id_statico_entry"])
        Elab1 = Elab1.reset_index(drop=True)

        # uno in meno perchè devo fare confronto tra i e i+1
        for i in range(L_GI-1):

            # se gli oggetti consecutivi sono uguali
            if Elab1.iloc[i+1, j+nC] == Elab1.iloc[i, j+nC] :

                # poni l'id successivo uguale a quello attuale
                Elab1.iloc[i+1, j] = Elab1.iloc[i, j] 

                ripetizioni.iloc[0, j] = ripetizioni.iloc[0, j] + 1


    Elab1 = Elab1.sort_values(["Lemma", "Id_statico_entry"])
    Elab1 = Elab1.reset_index(drop=True)
 

    print(Elab1)

    # creo un dataframe per gli ogetti univoci (L_GI-ripetizioni)

    label_oggetti_univoci = []

    for j in range(nC):
        label_oggetti_univoci.append("Oggetti_univoci_di_" + nomi_campi_prepared_terminology[j])

    # creo i dati per il df ripetizioni
    oggetti_univoci_content = []
    
    oggetti_univoci_content.append([ L_GI - ripetizioni.iloc[0, j] for j in range(nC) ])   
    

    # creo  il df ripetizioni
    oggetti_univoci = pd.DataFrame(oggetti_univoci_content, columns=label_oggetti_univoci)

    

    print("Il metaglossario Elab1 possiede i seguenti numeri di oggetti univoci:")

    print(np.transpose(oggetti_univoci))


    # Inizia il ciclo di sostituzioni degli ID con ID ordinati in linea con gli ID statici

    #  ossia:
    #  tutte le colonne sono ordinate per ID statici,
    #  un ciclo i scorre le colonne, e:
    #  un ciclo j scorre tutta la colonna, e:
    #  l'ID corrente(j) viene salvato come bersaglio da sostituire
    #  viene generato un ID del tipo x000000[contatore del ciclo j /ossia prestampaIDs(j,i)] e salvato come sostituto
    #  un ciclo k scorre tutta la colonna DALLA CELLA CORRENTE VERSO IL BASSO (onde evitare di sovrascrivere i precedenti) e sostituisce altre celle uguali al bersaglio con il sostuituto

    print("Viene eseguita la riclassificazione degli ID dei singoli oggetti per realizzare le tabelle relazionali del database...")

    # col_scan 1 To L_GI, 1 To nC
    # avvenuta_sost  1 To L_GI, 1 To nC

    #  va bene anche df_zeros = df * 0

    avvenuta_sost = pd.DataFrame(0, index=np.arange(L_GI), columns=label_IDs_prestampa)


    # ordino il glossario alfabeticamente per IDS, una sola volta
    Elab1 = Elab1.sort_values("Id_statico_entry")
    Elab1 = Elab1.reset_index(drop=True)

    # in col scan ci metto gli id di elab1 ordinati per ids
    col_scan = Elab1[label_IDs_prestampa]

    

    pd.options.mode.chained_assignment = None  # default='warn'
    # https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas

    # in VBA, solo negli offset accade che righe e colonne hanno il sistema ribaltato rispetto a x=0 e coordinate scambiate
    # nelle matrici si ragiona normalmente in (righe, colonne)

    for i in range(nC):
    # ciclo delle colonne
    # per l'ID statico non devo farlo ... ma non è più in ultima poizione

        for j in range(L_GI):
        #ciclo delle righe

            Bersaglio = col_scan.iloc[j, i]
            Sostituto = IDs_prestampa.iloc[j, i] # questi sono gli id 1000001 , 10000002, ecc

            

            for k in range(j, L_GI): #[j, j+1,...,L_GI-1, L_GI]
            # ciclo del check per una riga di tutti i duoi doppioni nella colonna
            # 'deve andare fino a L_GI-1 : deve controllare la colonna fino in fondo, ma senza modificare gli elementi prima della colonna j
            # 'ciclo di sola sostituzione: non mettere else

                

                if col_scan.iloc[k, i] == Bersaglio and avvenuta_sost.iloc[k, i] == 0:
                            
                    col_scan.iloc[k, i] = Sostituto                             
                    avvenuta_sost.iloc[k, i] = 1


    # incollo col_scan sulla parte ID di Elab 1
    
    Elab1[ label_IDs_prestampa ] = col_scan [label_IDs_prestampa]

    print(Elab1[ label_IDs_prestampa ])

    del IDs_prestampa
    del avvenuta_sost
    del col_scan

    # 'ora devo compattare gli ID per non lasciare buchi
    for j in range(nC):

        Elab1 = Elab1.sort_values([nomi_campi_prepared_terminology[j], "Id_statico_entry"])
        Elab1 = Elab1.reset_index(drop=True)
        

    Elab1 = Elab1.sort_values(["Id_statico_entry"])
    Elab1 = Elab1.reset_index(drop=True)

    print(Elab1)

    print("Vengono generate le tabelle per il database...")

    print("Viene generata la tabella delle entità Things con tutti gli oggetti del database e i loro Id relazionali...")

    # creazione della tabella things: id e oggetti
    # concat: axis: 0 per la concatenazione in colonna, 1 per la concatenazione in riga

    # concatena in colonna gli id di tutti gli oggetti
    # incolla uno sotto l'altra le colonne degli id
    Things_ID = pd.concat([Elab1[j] for j in nomi_campi_prepared_terminology], axis=0) 

    # concatena in colonna gli oggetti
     # incolla uno sotto l'altra le colonne degli oggetti
    Things_oggetti = pd.concat([Elab1[j] for j in label_IDs_prestampa], axis=0)

    # crea la tabella things
    # concatena in riga id e oggetti    
    Things = pd.concat([Things_ID, Things_oggetti], axis=1) # è dataframe

    # assegno il nome alle colonne
    Things.columns=['ID_db_Thing','Thing']

    # resetto gli indici altrimenti mi tiene gli indici di Elab1
    Things = Things.reset_index(drop=True)

    print(Things)

    del Things_ID
    del Things_oggetti

    print("Vengono generate le tabelle relazionali...")


    # ["Lemma", "Acronimo", "Definizione", "Ambito_riferimento", "Autore_definizione", "Posizione_definizione", "
    # Url_definizione", "Titolo_documento_fonte", "Autore_documento_fonte", "Host_documento_fonte", 
    # "Url_documento_fonte", "Commento_entry", "Data_inserimento_entry", "Id_statico_entry", "Admin_approval_switch"]
    
    # ID_db_

    is_Acronimo_of = pd.concat([ Elab1["ID_db_Acronimo"], Elab1["ID_db_Lemma"], Elab1["Acronimo"], Elab1["Lemma"] ], axis=1)

    is_Lemma_of = pd.concat( [Elab1["ID_db_Lemma"], Elab1["ID_db_Definizione"], Elab1["Lemma"], Elab1["Definizione"] ], axis=1)

    is_Ambito_riferimento_of = pd.concat([ Elab1["ID_db_Ambito_riferimento"], Elab1["ID_db_Definizione"], Elab1["Ambito_riferimento"], Elab1["Definizione"] ], axis=1)

    is_Autore_definizione_of = pd.concat([ Elab1["ID_db_Autore_definizione"], Elab1["ID_db_Definizione"], Elab1["Autore_definizione"], Elab1["Definizione"] ], axis=1)

    is_Posizione_definizione_of = pd.concat([ Elab1["ID_db_Posizione_definizione"], Elab1["ID_db_Definizione"], Elab1["Posizione_definizione"], Elab1["Definizione"] ], axis=1)

    is_Url_definizione_of = pd.concat([ Elab1["ID_db_Url_definizione"], Elab1["ID_db_Definizione"], Elab1["Url_definizione"], Elab1["Definizione"] ], axis=1)

    # is_Titolo_documento_fonte_of = pd.concat([ Elab1["ID_db_Ambito_riferimento"], Elab1["ID_db_Definizione"], Elab1["Ambito_riferimento"], Elab1["Definizione"] ], axis=1)

    is_Autore_documento_fonte_of = pd.concat([ Elab1["ID_db_Autore_documento_fonte"], Elab1["ID_db_Titolo_documento_fonte"], Elab1["Autore_documento_fonte"], Elab1["Titolo_documento_fonte"] ], axis=1)

    is_Host_documento_fonte_of = pd.concat([ Elab1["ID_db_Host_documento_fonte"], Elab1["ID_db_Titolo_documento_fonte"], Elab1["Host_documento_fonte"], Elab1["Titolo_documento_fonte"] ], axis=1)

    is_Url_documento_fonte_of = pd.concat([ Elab1["ID_db_Url_documento_fonte"], Elab1["ID_db_Titolo_documento_fonte"], Elab1["Url_documento_fonte"], Elab1["Titolo_documento_fonte"] ], axis=1)

    is_Commento_entry_of = pd.concat([ Elab1["ID_db_Commento_entry"], Elab1["ID_db_Id_statico_entry"], Elab1["Commento_entry"], Elab1["Id_statico_entry"] ], axis=1)
    
    is_Data_inserimento_entry_of = pd.concat([ Elab1["ID_db_Data_inserimento_entry"], Elab1["ID_db_Id_statico_entry"], Elab1["Data_inserimento_entry"], Elab1["Id_statico_entry"] ], axis=1)
    

    # is_Id_statico_entry_of è lunga nC*L_GI perchè collega gli id_statici a nC entità del database

    Id_statico_entry_impilati_per_nC = pd.concat([Elab1["Id_statico_entry"] for j in range(nC)], axis=0)   
    # resetto gli indici altrimenti mi tiene gli indici di Elab1
    Id_statico_entry_impilati_per_nC = Id_statico_entry_impilati_per_nC.reset_index(drop=True)
    Id_statico_entry_impilati_per_nC = pd.DataFrame(Id_statico_entry_impilati_per_nC) # è dataframe

    ID_db_Id_statico_entry_impilati_per_nC = pd.concat([Elab1["ID_db_Id_statico_entry"] for j in range(nC)], axis=0)  
    # resetto gli indici altrimenti mi tiene gli indici di Elab1
    ID_db_Id_statico_entry_impilati_per_nC = ID_db_Id_statico_entry_impilati_per_nC.reset_index(drop=True)
    ID_db_Id_statico_entry_impilati_per_nC = pd.DataFrame(ID_db_Id_statico_entry_impilati_per_nC) # è dataframe
  

   
    is_Id_statico_entry_of = pd.concat( [ ID_db_Id_statico_entry_impilati_per_nC, Id_statico_entry_impilati_per_nC, Things ], axis=1)




    is_Admin_approval_switch_of = pd.concat([ Elab1["ID_db_Admin_approval_switch"], Elab1["ID_db_Id_statico_entry"], Elab1["Admin_approval_switch"], Elab1["Id_statico_entry"] ], axis=1)
    
    del Elab1


    ###########

    # ELIMINA LE RIGHE RIPETUTE dalle tabelle relazionali

    print("La tabella delle entità e le tabelle relazionali vengono ripulite degli elementi ridondanti")


    Tabelle_relazionali = [is_Acronimo_of, is_Lemma_of, is_Ambito_riferimento_of, is_Autore_definizione_of, is_Posizione_definizione_of, is_Url_definizione_of, is_Autore_documento_fonte_of, is_Host_documento_fonte_of, is_Url_documento_fonte_of, is_Commento_entry_of, is_Data_inserimento_entry_of, is_Id_statico_entry_of, is_Admin_approval_switch_of]


    label_righe_eliminate = []

    for i in range(nC):
        label_righe_eliminate.append("Righe_eliminate_di_" + nomi_campi_prepared_terminology[i])

    # creo i dati per il df righe_eliminate
    righe_eliminate_content = []
    
    righe_eliminate_content.append([ 0 for j in range(nC) ])

    # creo il df righe_eliminate
    righe_eliminate = pd.DataFrame(righe_eliminate_content, columns=label_righe_eliminate)

    j=0 # serve solo per tracciare il n di righe eliminate

    for tabella in Tabelle_relazionali:

        colonne_tabella = list(tabella.columns.values)        

        tabella = tabella.sort_values( [ colonne_tabella[0], colonne_tabella[1] ] )
        tabella = tabella.reset_index(drop=True)
    
        last_ID_unique_A = tabella.iloc[0, 0] 
        last_ID_unique_B = tabella.iloc[0, 1] 


        for i in range(1,L_GI): # da 1 a L_GI

            if tabella.iloc[i, 0] == last_ID_unique_A and tabella.iloc[i, 1] == last_ID_unique_B:

                tabella.iloc[i, :] = "ELIMINARE"
                righe_eliminate.iloc[0, j] = righe_eliminate.iloc[0, j] + 1


            # handle Nan
            elif np.isnan(tabella.iloc[i, 0]) and np.isnan(last_ID_unique_A) and tabella.iloc[i, 1] == last_ID_unique_B:

                tabella.iloc[i, :] = "ELIMINARE"
                righe_eliminate.iloc[0, j] = righe_eliminate.iloc[0, j] + 1

            elif tabella.iloc[i, 0] == last_ID_unique_A and np.isnan(tabella.iloc[i, 1]) and np.isnan(last_ID_unique_B):

                tabella.iloc[i, :] = "ELIMINARE"
                righe_eliminate.iloc[0, j] = righe_eliminate.iloc[0, j] + 1

            elif np.isnan(tabella.iloc[i, 0]) and np.isnan(last_ID_unique_A) and np.isnan(tabella.iloc[i, 1]) and np.isnan(last_ID_unique_B):

                tabella.iloc[i, :] = "ELIMINARE"
                righe_eliminate.iloc[0, j] = righe_eliminate.iloc[0, j] + 1



            else:
                last_ID_unique_A = tabella.iloc[i, 0] 
                last_ID_unique_B = tabella.iloc[i, 1] 

        

        
        indexNames = tabella[ tabella[colonne_tabella[0]] == "ELIMINARE" ].index
 
        # Delete these row indexes from dataFrame
        tabella.drop(indexNames, inplace=True)
        tabella = tabella.reset_index(drop=True)

        print(tabella)

        print("***********************************")

        j=j+1

    print(np.transpose(righe_eliminate))


    # ####################

    displaying_terminology.objects.all().delete()
    print("Eliminati tutti i dati dentro displaying_terminology!")


    # il 3-ciclo è momentaneamente dsattivato

    # in alcuni non li trova
    # in alcuni non li elimina


************************************

  j=0 # serve solo per tracciare il n di righe eliminate

    tabelle_database = [Things]
    tabelle_database = tabelle_database.append(Tabelle_relazionali)

    nomi_tabelle_database = ["Things"]
    nomi_tabelle_database = nomi_tabelle_database.append(nomi_Tabelle_relazionali)

    modelli_metaglossario = [ model_Things, model_is_Acronimo_of, model_is_Lemma_of, model_is_Ambito_riferimento_of, model_is_Autore_definizione_of, model_is_Posizione_definizione_of, model_is_Url_definizione_of, model_is_Autore_documento_fonte_of, model_is_Url_documento_fonte_of, model_is_Commento_entry_of, model_is_Data_inserimento_entry_of, model_is_Id_statico_entry_of, model_is_Admin_approval_switch_of ]
    nomi_modelli_metaglossario = [ "model_Things", "model_is_Acronimo_of", "model_is_Lemma_of", "model_is_Ambito_riferimento_of", "model_is_Autore_definizione_of", "model_is_Posizione_definizione_of", "model_is_Url_definizione_of", "model_is_Autore_documento_fonte_of", "model_is_Url_documento_fonte_of", "model_is_Commento_entry_of", "model_is_Data_inserimento_entry_of", "model_is_Id_statico_entry_of", "model_is_Admin_approval_switch_of" ]

    n_tabelle = len(tabelle_database)

    for k in range(n_tabelle):

        tabella = tabelle_database[k]
        modello = modelli_metaglossario[k]

        nomi_campi_modelli = [field.name for field in prepared_terminology._meta.get_fields()[1:]]

        colonne_tabella = list(tabella.columns.values) 

        L_tabella = len(tabella.index)       

        # dovrebbero essere già ordinate, ma non importa
        tabella = tabella.sort_values( [ colonne_tabella[0], colonne_tabella[1] ] )
        tabella = tabella.reset_index(drop=True)

        for i in range(L_tabella): 
            
            # non ci sono NaN
            
            modello.objects.create(field_A=var_col_A[i], field_B=var_col_B[i], field_C=var_col_C[i])



**************************


class model_Titolo_documento_fonte(models.Model): 

    ID = models.CharField(max_length=10, primary_key=True)

    Titolo_documento_fonte = models.TextField(blank=True, null=True)

    Url_documento_fonte = models.ManyToManyField('model_Url_documento_fonte', blank=True, null=True)
    Autore_documento_fonte = models.ManyToManyField('model_Autore_documento_fonte', blank=True, null=True)
    Host_documento_fonte = models.ManyToManyField('model_Host_documento_fonte', blank=True, null=True)
    Definizione = models.ManyToManyField('model_Things', blank=True, null=True)

    class Meta:
        ordering = ['Titolo_documento_fonte', 'ID']

    def __str__(self):                
        return  "%s [ %s ]"  %  (self.Titolo_documento_fonte, self.ID)


class model_Url_documento_fonte(models.Model): 

    ID = models.CharField(max_length=10, primary_key=True)

    Url_documento_fonte = models.TextField(blank=True, null=True)

    Titolo_documento_fonte = models.ManyToManyField('model_Titolo_documento_fonte', blank=True, null=True)
    

    class Meta:
        ordering = ['Url_documento_fonte', 'ID']

    def __str__(self):                
        return  "%s [ %s ]"  %  (self.Url_documento_fonte, self.ID)



class model_Autore_documento_fonte(models.Model): 

    ID = models.CharField(max_length=10, primary_key=True)

    Autore_documento_fonte = models.TextField(blank=True, null=True)

    Titolo_documento_fonte = models.ManyToManyField('model_Titolo_documento_fonte', blank=True, null=True)
    

    class Meta:
        ordering = ['Autore_documento_fonte', 'ID']

    def __str__(self):                
        return  "%s [ %s ]"  %  (self.Autore_documento_fonte, self.ID)



class model_Host_documento_fonte(models.Model): 

    ID = models.CharField(max_length=10, primary_key=True)

    Host_documento_fonte = models.TextField(blank=True, null=True)

    Titolo_documento_fonte = models.ManyToManyField('model_Titolo_documento_fonte', blank=True, null=True)
    

    class Meta:
        ordering = ['Host_documento_fonte', 'ID']

    def __str__(self):                
        return  "%s [ %s ]"  %  (self.Host_documento_fonte, self.ID)



        ********************


        from app_metaglossario.entity_relationship_models import *
from app_metaglossario.node_models import *
from app_metaglossario.models import displaying_terminology


def algoritmo_WD():

    print("Viene richiamato l'algoritmo WD!")

    # algoritmo per organizzare i dati per la visualizzazione
    # la chiave è costruire una vista che permette di vedere un oggetto alla volta, 
    # col punto di vista incentrato su quell'oggetto, circondato dai related.

    # nota: ci sono dati con lo stesso ID perchè sono i lemmi inglesi eliminati

    import numpy as np
    import pandas as pd

    # importa la tabella excel Elab 1 e salvala come dataframe

    import os    
    from django.contrib.staticfiles import finders

    saving_file_name = 'Elab1.xlsx'

    saving_folder_name = 'saved_dataframes'

    finders.find(saving_folder_name)
    searched_locations = finders.searched_locations
    df_dir = os.path.join(searched_locations[0]+r'\\'+saving_folder_name+r'\\'+saving_file_name)

    Elab1 = pd.read_excel(df_dir, head=True, index_col=0)

    

    print("Viene importato il dataframe Elab1 dalla directory %s !" % df_dir)

    print(Elab1)

    

    # usala per riempire il modello node, seguendo la struttura relazionale del metaglossario
    # aggiungi commento entri e admin approval switch

    L_GI = len(Elab1.index)
    nC = len(Elab1.columns)
    
    #il risultato di questa operazione è automaticamente un float!
    # metto int dentro try per correggerlo


    if (nC % 2) != 0:
        raise ValueError("ERRORE! Il file in ingresso Elab1 deve necessariamente avere un numero di colonne pari, perchè formato da ID_db ed entità corrispondenti!")

    
    nC = int(nC/2)

    print("Dimensioni del dataframe:")
    print("Righe (L_GI): %s" % L_GI)
    print("Colonne (nC): %s" % nC)  

    # salvo i nomi delle colonne
    label_Elab1 = list(Elab1.columns)

    #setta la dimensione dell'ID    
    ID_dimension = 1000000

    print("*****************************************")

    model_node.objects.all().delete()
    print("Eliminati tutti i dati dentro model_node!")

    print("Il modello nodale viene riempito sulla base dei dati contenuti in Elab1...")


    # Per ogni entità, compila il modello nodale

    # ["Lemma", "Acronimo", "Definizione", "Ambito_riferimento", "Autore_definizione", "Posizione_definizione", "
    # Url_definizione", "Titolo_documento_fonte", "Autore_documento_fonte", "Host_documento_fonte", 
    # "Url_documento_fonte", "Commento_entry", "Data_inserimento_entry", "Id_statico_entry", "Admin_approval_switch"]
    
    # Lemma -- acronimi, id statico,     

    Elab1 = Elab1.sort_values(["Lemma", "Id_statico_entry"])
    Elab1 = Elab1.reset_index(drop=True)
    


****************************